This page contains general information about [[Nvidia]]'s [[Graphics processing unit|GPUs]] and videocards based on official Nvidia specifications.

<div class="toclimit-3">__TOC__</div>

==DirectX version note==
[[DirectX]] version indicates which [[Direct3D]] graphics acceleration operations the card supports.
* Direct3D 6.0 - [[Texture mapping|Multitexturing]]
* Direct3D 7.0 - Hardware [[Transform and lighting|Transformation, Clipping and Lighting]] (TCL/T&L)
* Direct3D 8.0 - Pixel [[Shader]] 1.1 & Vertex Shader 1.1
* Direct3D 8.1 - Pixel Shader 1.4 & Vertex Shader 1.1
* Direct3D 9.0 - Shader Model 2.0
* Direct3D 9.0a - Pixel Shader 2.0a & Vertex Shader 2.0a
* Direct3D 9.0c - Shader Model 3.0, [[GPGPU]]
* Direct3D 9.0L - [[Windows Vista]] only, Vista version of DirectX 9.0c, Shader Model 3.0, Windows Graphics Foundation 1.0, [[DXVA]] 1.0, [[GPGPU]]
* Direct3D 10.0 - Windows Vista/Windows 7, Shader Model 4.0, Windows Graphics Foundation 2.0, DXVA 2.0, [[GPGPU]]
* Direct3D 10.1 - Windows Vista SP1/Windows 7, Shader Model 4.1, Windows Graphics Foundation 2.1, DXVA 2.1, [[GPGPU]]
* Direct3D 11.0 - [[Windows Vista]] (With Patch)/[[Windows 7]], Shader Model 5.0, Tessellation, Multithreaded rendering, Compute shaders, supported by hardware and software running Direct3D 9/10/10.1, [[GPGPU]]
* Direct3D 11.1 - [[Windows 8]], Stereoscopic 3D Rendering, [[GPGPU]]
* Direct3D 12.0 -

==OpenGL version note==
[[OpenGL]] version indicates which graphics acceleration operations the card supports.
* OpenGL 1.1 - Texture objects
* OpenGL 1.2 - 3D Ttextures, BGRA and [[packed pixel]] formats
* OpenGL 1.3 - [[Texture mapping|Multitexturing]], [[multisampling]], texture compression
* OpenGL 1.4 - Depth textures
* OpenGL 1.5 - [[Vertex Buffer Object|VBO]], Occlusion Queries
* OpenGL 2.0 - [[GLSL]] 1.1, [[Multiple Render Targets|MRT]], Non Power of Two textures, [[Point Sprites]], Two-sided stencil
* OpenGL 2.1 - [[GLSL]] 1.2, Pixel Buffer Object (PBO), sRGB Textures
* OpenGL 3.0 - [[GLSL]] 1.3, Texture Arrays, Conditional rendering, FBO
* OpenGL 3.1 - [[GLSL]] 1.4, Instancing, Texture Buffer Object, Uniform Buffer Object, Primitive restart
* OpenGL 3.2 - [[GLSL]] 1.5, Geometry Shaders, Multi-sampled textures
* OpenGL 3.3 - [[GLSL]] 3.30 Backports as much functionality possible from the OpenGL 4.0 specification
* OpenGL 4.0 - [[GLSL]] 4.00 Tessellation on GPU, shaders with 64-bit precision
* OpenGL 4.1 - [[GLSL]] 4.10 Developer-friendly debug outputs, compatibility with OpenGL ES 2.0
* OpenGL 4.2 - [[GLSL]] 4.20 Shaders with atomic counters, transform feedback, shader packing, performance improvements
* OpenGL 4.3 - [[GLSL]] 4.30 Shader storage buffer objects, Texture parameter queries, [[Ericsson Texture Compression|ETC2/EAC]], Increased memory security, A multi-application robustness extension
* OpenGL 4.4 - [[GLSL]] 4.40 Buffer Placement Control, Efficient Asynchronous Queries, Shader Variable Layout, Efficient Multiple Object Binding, Streamlined Porting of Direct3D applications, Bindless Texture Extension, Sparse Texture Extension

==Field explanations==
The fields in the table listed below describe the following:

* '''Model''' - The marketing name for the processor assigned by Nvidia.
* '''Launch''' - Date of release for the processor.
* '''Code name''' - The internal engineering codename for the processor (typically designated by an NVXY name and later GXY where X is the series number and Y is the schedule of the project for that generation).
* '''[[Semiconductor device fabrication|Fab]]''' - Fabrication process. Average feature size of components of the processor.
* '''[[Bus (computing)|Bus interface]]''' - Bus by which the graphics processor is attached to the system (typically an expansion slot, such as PCI, AGP, or PCI-Express).
* '''[[Random-access memory|Memory]]''' - The amount of graphics memory available to the processor.
* '''SM Count''' - Number of streaming multiprocessors.
* '''Core [[Clock rate|clock]]''' - The factory core clock frequency (while some manufacturers adjust clocks lower and higher, this number will always be the reference clocks used by Nvidia).
* '''Memory clock''' - The factory effective memory clock frequency (while some manufacturers adjust clocks lower and higher, this number will always be the reference clocks used by Nvidia). All DDR/GDDR memories operate at half this frequency, except for GDDR5, which operates at one quarter of this frequency.
* '''Core config''' - The layout of the graphics pipeline, in terms of functional units. Over time the number, type, and variety of functional units in the GPU core has changed significantly; before each section in the list there is an explanation as to what functional units are present in each generation of processors. In later models, shaders are integrated into a unified shader architecture, where any one shader can perform any of the functions listed.
* '''[[Fillrate]]''' - Maximum theoretical fillrate in textured pixels per second. This number is generally used as a "maximum throughput number" for the GPU and generally, a higher fillrate corresponds to a more powerful (and faster) GPU.
* '''Memory subsection'''
** '''Bandwidth''' - Maximum theoretical bandwidth for the processor at factory clock with factory bus width. GB=10^9 bytes.
** '''Bus type''' - Type of memory bus or buses utilized.
** '''Bus width''' - Maximum bit width of the memory bus or buses utilized. This will always be a factory bus width.
* '''API support section'''
** '''DirectX''' - Maximum version of DirectX fully supported.
** '''OpenGL''' - Maximum version of OpenGL fully supported.
* '''Features''' - Additional features that are not standard as a part of the two graphics libraries.

==Comparison tables: Desktop GPUs==

===Pre-GeForce===

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTexels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|[[NV1|STG-2000]]
|September 1995
|NV1
|?
|PCI
|2<br>4
|12
|75
|1:1:1
|12
|12
|12
|0
|0.6
|EDO<br>VRAM
|64
|n/a
|n/a
|-
!style="text-align:left"|[[Riva 128|Riva128]]
|April 1997
|NV3
|350
|PCI
|4
|100
|100
|1:1:1
|100
|100
|100
|0
|1.6
|SDR
|128
|5.0
|1.0
|-
!style="text-align:left"|Riva128ZX
|February 23, 1998
|NV3
|350
|AGP 2x, PCI
|8
|100
|100
|1:1:1
|100
|100
|100
|0
|1.6
|SDR
|128
|5.0
|1.0
|-
!style="text-align:left"|[[Riva TNT]]
|March 23, 1998
|NV4
|350
|AGP 2x, PCI
|8<br>16
|90
|110
|2:2:2
|180
|180
|180
|0
|1.76
|SDR
|128
|5.0
|1.2
|-
!style="text-align:left"|Vanta
|March 22, 1999
|NV6
|250
|AGP 4x
|16
|100
|125
|2:2:2
|200
|200
|200
|0
|1
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|Vanta LT
|March, 2000
|NV6
|250
|AGP 4x
|8<br>16
|80
|100
|2:2:2
|160
|160
|160
|0
|0.8
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|Riva TNT2 M64
|October, 1999
|NV6
|250
|AGP 4x, PCI
|8, 16<br>32
|125
|150
|2:2:2
|250
|250
|250
|0
|1.2
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]]
|March 15, 1999
|NV5
|250
|AGP 4x, PCI
|16<br>32
|125
|150
|2:2:2
|250
|250
|250
|0
|2.4
|SDR
|128
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]] Pro
|October 12, 1999
|NV5
|220
|AGP 4x
|32
|143
|166
|2:2:2
|286
|286
|286
|0
|2.656
|SDR
|128
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]] Ultra
|March 15, 1999
|NV5
|250
|AGP 4x
|16<br>32
|150
|183
|2:2:2
|300
|300
|300
|0
|2.928
|SDR
|128
|6.0
|1.2
|}

*<sup>1</sup> [[Pixel pipeline]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce256 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 256 |GeForce 256 ]]</div>
* All models are manufactured with a 220&nbsp;nm fabrication process
* All models support [[DirectX]] 7.0 and [[OpenGL]] 1.2
* All models support hardware Transform and Lighting (T&L) and Cube Environment Mapping

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce256
|October 11, 1999
|NV10
|AGP 4x<br>PCI
|32<br>64
|120
|166
|4:4:4
|480
|480
|480
|0
|2.656
|SDR
|128
|-
!style="text-align:left"|GeForce256 DDR
|February 1, 2000
|NV10
|AGP 4x<br>PCI
|32<br>64
|120
|300
|4:4:4
|480
|480
|480
|0
|4.8
|DDR
|128
|}

*<sup>1</sup> [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce2 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 2 Series|GeForce 2 Series]]</div>

* All models are manufactured with a 180&nbsp;nm manufacturing process
* All models support [[DirectX]] 7 and [[OpenGL]] 1.2
* All models support TwinView Dual-Display Architecture, Second Generation Transform and Lighting (T&L), NVIDIA Shading Rasterizer (NSR), High-Definition Video Processor (HDVP)
* GeForce2 MX models support Digital Vibrance Control (DVC)

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce2 MX IGP + nForce 220/420
|June 4, 2001
|NV1A
|FSB
|Up to 32 system RAM
|175
|266
|2:4:2
|350
|350
|700
|0
|2.128<br>4.256
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce2 MX200
|March 3, 2001
|NV11
|AGP 4x<br>PCI
|32<br>64
|175
|166
|2:4:2
|350
|350
|700
|0
|1.328
|SDR
|64
|-
!style="text-align:left"|GeForce2 MX
|June 28, 2000
|NV11
|AGP 4x<br>PCI
|32<br>64
|175
|166
|2:4:2
|350
|350
|700
|0
|2.656
|SDR
|128
|-
!style="text-align:left"|GeForce2 MX400
|March 3, 2001
|NV11
|AGP 4x<br>PCI
|32<br>64
|200
|166 (SDR)<br>332 (DDR)
|2:4:2
|400
|400
|800
|0
|2.656
|SDR<br>DDR
|128 (SDR)<br>64 (DDR)
|-
!style="text-align:left"|GeForce2 GTS
|April 26, 2000
|NV15
|AGP 4x<br>PCI
|32<br>64
|200
|332
|4:8:4
|800
|800
|1600
|0
|5.312
|DDR
|128
|-
!style="text-align:left"|GeForce2 Pro
|December 5, 2000
|NV15
|AGP 4x<br>PCI
|32<br>64
|200
|400
|4:8:4
|800
|800
|1600
|0
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce2 Ti
|October 1, 2001
|NV15
|AGP 4x<br>PCI
|32<br>64
|250
|400
|4:8:4
|1000
|1000
|2000
|0
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce2 Ultra
|August 14, 2000
|NV16
|AGP 4x<br>PCI
|64
|250
|460
|4:8:4
|1000
|1000
|2000
|0
|7.36
|DDR
|128
|}

*<sup>1</sup> [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce3 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 3 Series|GeForce 3 Series]]</div>

* All models are manufactured with a 150&nbsp;nm manufacturing process
* All models support [[DirectX]] 8.0 and [[OpenGL]] 1.3
* All models support 3D Textures, Lightspeed Memory Architecture (LMA), nFiniteFX Engine, Shadow Buffers

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce3 Ti200
|October 1, 2001
|NV20
|AGP 4x<br>PCI
|64<br>128
|175
|400
|4:1:8:4
|700
|700
|1400
|42.75
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce3
|February 27, 2001
|NV20
|AGP 4x<br>PCI
|64
|200
|460
|4:1:8:4
|800
|800
|1600
|50
|7.36
|DDR
|128
|-
!style="text-align:left"|GeForce3 Ti500
|October 1, 2001
|NV20
|AGP 4x<br>PCI
|64<br>128
|240
|500
|4:1:8:4
|960
|960
|1920
|60
|8
|DDR
|128
|}

*<sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce4 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 4 Series|GeForce 4 Series]]</div>

* All models are manufactured with a 150&nbsp;nm manufacturing process
* All models support Accuview Antialiasing (AA), Lightspeed Memory Architecture II (LMA II), nView

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support (version)
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|GeForce4 MX IGP + nForce2
|October 1, 2002
|NV1F
|FSB
|Up to 128 system RAM
|250
|266<br>400<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|2:0:4:2
|500
|500
|1000
|0
|2.128<br>6.4<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR
|64<br>128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX420
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64
|250
|166
|2:0:4:2
|500
|500
|1000
|0
|2.656
|SDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440 SE
|2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|250
|332
|2:0:4:2
|500
|500
|1000
|0
|5.312
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce MX4000 
|December 14, 2003
|NV18B
|AGP 8x<br>PCI
|64<br />128
|250
|332
|2:0:4:2
|500
|500
|1000
|0
|2.656
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce PCX4300 
|February 19, 2004
|NV18B
|PCI-E x16
|128
|250
|666
|2:0:4:2
|500
|500
|1000
|0
|5.328
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|275
|400
|2:0:4:2
|550
|550
|1100
|0
|6.4
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440 8x
|September 25, 2002
|NV18
|AGP 8x<br>PCI
|64<br>128
|275
|500
|2:0:4:2
|550
|550
|1100
|0
|8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX460
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|300
|550
|2:0:4:2
|600
|600
|1200
|0
|8.8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Ti4200
|April 16, 2002
|NV25
|AGP 4x
|64<br>128
|250
|444 (128 MB)<br>500 (64 MiB)
|4:2:8:4
|1000
|1000
|2000
|125
|7.104 (128 MB)<br>8 (64 MB)
|DDR
|64<br>128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4400
|February 6, 2002
|NV25
|AGP 4x
|128
|275
|550 
|4:2:8:4
|1100
|1100
|2200
|137.5
|8.8
|DDR
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4800 SE
|January 20, 2003
|NV28
|AGP 8x
|128
|275
|550
|4:2:8:4
|1100
|1100
|2200
|137.5
|8.8
|'''DDR'''
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4600
|February 6, 2002
|NV25
|AGP 4x
|128
|300
|650 
|4:2:8:4
|1200
|1200
|2400
|150
|10.4
|DDR
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4800
|January 20, 2003
|NV28
|AGP 8x
|128
|300
|640
|4:2:8:4
|1200
|1200
|2400
|150
|10.4
|DDR
|128
|8.1
|1.3
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support (version)
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
|}

*<sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=5 style="text-align:center;" | Features
|-
! nFiniteFX II Engine
! Video Processing Engine (VPE)
|-
! style="text-align:left;"| GeForce4 MX420
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 MX440 SE
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 MX4000
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 PCX4300
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 MX440
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 MX440 8X
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 MX460
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce4 Ti4200
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce4 Ti4400
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce4 Ti4600
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce4 Ti4800
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|}

===GeForce FX (5xxx) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce FX Series|GeForce FX Series]]</div>

* All models support [[DirectX]] 9.0b and [[OpenGL]] 1.5 (2.1 (software) with latest drivers)
* The GeForce FX Series runs vertex shaders in an array

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce FX 5200
|March 2003
|NV34
|150
|AGP 8X<br>PCI
|64<br>128
|250
|400
|4:1:4:4
|1000
|1000
|1000
|62.5
|3.2<br>6.4<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5200 Ultra
|March 6, 2003
|NV34
|150
|AGP 8X
|64<br>128
|325
|650
|4:1:4:4
|1300
|1300
|1300
|81.25
|10.4
|DDR
|128
|-
!style="text-align:left"|GeForce PCX 5300
|March 17, 2004
|NV34
|150
|PCI-E x16
|128
|250
|400
|4:1:4:4
|1000
|1000
|1000
|62.5
|3.2<br>6.4<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5500
|March 2004
|NV34B
|140
|AGP 8X<br>AGP 4X<br>PCI
|64<br>128<br>256
|270
|400
|4:1:4:4
|1080
|1080
|1080
|67.5
|3.2<br>6.4<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5600 XT
|Oct 2003
|NV31
|130
|AGP 8X
|64<br>128
|235
|400
|4:1:4:4
|940
|940
|940
|58.75
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600
|March 2003
|NV31
|130
|AGP 8X<br>PCI
|64<br>128<br>256
|325
|550
|4:1:4:4
|1300
|1300
|1300
|81.25
|8.8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600 Ultra
|March 6, 2003
|NV31
|130
|AGP 8X
|64<br>128
|350
|700
|4:1:4:4
|1400
|1400
|1400
|87.5
|11.2
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600 Ultra Rev.2
|March 6, 2003
|NV31
|130
|AGP 8X
|64<br>128
|400
|800
|4:1:4:4
|1600
|1600
|1600
|100
|12.8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 VE
|Sept 2004
|NV36
|130
|AGP 8X
|128<br>256
|235
|400
|4:3:4:4
|940
|940
|940
|106.5
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 LE
|March 2004
|NV36
|130
|AGP 8X
|128<br>256
|250
|400
|4:3:4:4
|1000
|1000
|1000
|187.5
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700
|2003
|NV36
|130
|AGP 8X
|128<br>256
|425
|500
|4:3:4:4
|1700
|1700
|1700
|318.75
|8
|DDR
|128
|-
!style="text-align:left"|GeForce PCX 5750
|March 17, 2004
|NV36
|130
|PCI-E x16
|128
|425
|500
|4:3:4:4
|1700
|1700
|1700
|318.75
|8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 Ultra
|October 23, 2003
|NV36
|130
|AGP 8X
|128<br>256
|475
|900
|4:3:4:4
|1900
|1900
|1900
|356.25
|14.4
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5700 Ultra GDDR3
|March 15, 2004
|NV36
|130
|AGP 8X
|128<br>256
|475
|950
|4:3:4:4
|1900
|1900
|1900
|356.25
|15.2
|GDDR3
|128
|-
!style="text-align:left"|GeForce FX 5800
|January 27, 2003
|NV30
|130
|AGP 8X
|128
|400
|800
|4:2:8:4
|1600
|1600
|3200
|200
|12.8
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5800 Ultra
|January 27, 2003
|NV30
|130
|AGP 8X
|256
|500
|1000
|4:2:8:4
|2000
|2000
|4000
|250
|16
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5900 ZT
|December 15, 2003
|NV35
|130
|AGP 8X
|128
|325
|700
|4:3:8:4
|1300
|1300
|2600
|343.75
|22.4
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900 XT
|2003
|NV35
|130
|AGP 8X
|128
|390
|700
|4:3:8:4
|1600
|1600
|3200
|300
|22.4
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900
|May 2003
|NV35
|130
|AGP 8X
|128
|400
|850
|4:3:8:4
|1600
|1600
|3200
|300
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900 Ultra
|May 12, 2003
|NV35
|130
|AGP 8X
|128<br>256
|450
|850
|4:3:8:4
|1800
|1800
|3600
|337.5
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce PCX 5900
|March 17, 2004
|NV35
|130
|PCI-E x16
|128<br>256
|450
|850
|4:3:8:4
|1800
|1800
|3600
|337.5
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5950 Ultra
|October 23, 2003
|NV38
|130
|AGP 8X
|256
|475
|950
|4:3:8:4
|1900
|1900
|3800
|356.25
|30.4
|DDR
|256
|-
!style="text-align:left"|GeForce PCX 5950
|February 17, 2004
|NV38
|130
|PCI-E x16
|256
|475
|950
|4:3:8:4
|1900
|1900
|3800
|356.25
|30.4
|GDDR3
|256
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce 6 (6xxx) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 6 Series|GeForce 6 Series]]</div>

* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1
* All models support Transparency [[Spatial anti-aliasing|AA]] (starting with version 91.47 of the ForceWare drivers) and PureVideo

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce 6100 + nForce 410/430
|October 20, 2005
|MCP51
|90
|HyperTransport
|Up to 256 system RAM
|425
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|850
|425
|850
|106.25
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 SE + nForce 430
|June 2006
|MCP61
|90
|HyperTransport
|Up to 256 system RAM
|425
|400<br>800<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|2:1:2:1
|850
|425
|850
|106.25
|3.2<br>16.0<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 LE + nForce 430
|June 2006
|MCP61
|90
|HyperTransport
|Up to 256 system RAM
|425
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|850
|425
|850
|106.25
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 + nForce 430
|October 20, 2005
|MCP51
|90
|HyperTransport
|Up to 256 system RAM
|475
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|950
|475
|950
|118.75
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6200 LE
|2005
|NV44
|110
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|532
|2:1:2:2
|700
|700
|700
|87.5
|4.256
|DDR
|64
|-
!style="text-align:left"|GeForce 6200A
|April 4, 2005
|NV44A
|110
|AGP 8x
|128
|350
|500
|4:2:4:4
|1400
|1400
|1400
|175
|4
|DDR
|64
|-
!style="text-align:left"|GeForce 6200 
|October 12, 2004 (PCI-E)<br>January 17, 2005 (AGP)
|NV43
|110
|AGP 8x<br>PCI<br>PCI-E x16
|128<br>256
|300
|550
|4:3:4:2
|1200
|600
|1200
|225
|8.8
|DDR2
|128
|-
!style="text-align:left"|GeForce 6200 TurboCache
|December 15, 2004
|NV44
|110
|PCI-E x16
|128<br>256 onboard + 16/32/64/128 System RAM
|350
|700
|4:3:4:2
|1400
|700
|1400
|262.5
|5.6
|DDR
|64
|-
!style="text-align:left"|GeForce 6500
|October 1, 2005
|NV44
|110
|PCI-E x16
|128<br>256 
|400
|666
|4:3:4:2
|1600
|800
|1600
|300
|5.328
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600 LE
|2005
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|300
|400
|4:3:4:4
|1200
|1200
|1200
|225
|6.4
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600
|August 12, 2004
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|300
|550
|8:3:8:4
|2400
|1200
|2400
|225
|8.8
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600 GT
|August 12, 2004 (PCI-E)<br>November 14, 2004 (AGP)
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|500
|950 (AGP)<br>1000 (PCI-E)
|8:3:8:4
|4000
|2000
|4000
|375
|14.4 (AGP)<br>16 (PCI-E)
|GDDR3
|128
|- 
!style="text-align:left"|GeForce 6800 LE
|July 22, 2004 (AGP)<br>January 16, 2005 (PCI-E)
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128 
|320 (AGP)<br>325 (PCI-E)
|700
|8:4:8:8
|2560 (AGP)<br>2600 (PCI-E)
|2560 (AGP)<br>2600 (PCI-E)
|2560 (AGP)<br>2600 (PCI-E)
|320 (AGP)<br>325 (PCI-E)
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800 XT
|September 30, 2005
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|256
|325
|700
|8:4:8:8
|2600 
|2600 
|2600 
|325 
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800
|April 14, 2004 (AGP)<br>November 8, 2004 (PCI-E)
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128<br>256 
|325
|700
|12:5:12:12
|3900
|3900
|3900
|406.25
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800 GTO 
|April 14, 2004 
|NV45
|130
|PCI-E x16
|256 
|350
|900
|12:5:12:12
|4200
|4200
|4200
|437.5
|28.8
|GDDR3
|256
|-
!style="text-align:left"|GeForce 6800 GS 
|November 7, 2005 (PCI-E)<br>December 8, 2005 (AGP) 
|NV40 (AGP)<br>NV42 (PCI-E)
|130
|PCI-E x16
|128<br>256
|425
|1000
|12:5:12:12
|5100
|5100
|5100
|531.25
|32
|GDDR3
|256
|-
!style="text-align:left"|GeForce 6800 GT
|May 4, 2004 (AGP)<br>June 28, 2004 (PCI-E)
|NV40 (AGP)<br>NV45 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|1000
|16:6:16:16
|5600
|5600
|5600
|525
|32
|GDDR3
|256
|- 
!style="text-align:left"|GeForce 6800 Ultra
|May 4, 2004 (AGP)<br>June 28, 2004 (PCI-E)<br>March 14, 2005 (512 MiB)
|NV40 (AGP)<br>NV45 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|256<br>512
|400
|1050 (512 MiB)<br>1100 (256 MiB)
|16:6:16:16
|6400
|6400
|6400
|600
|33.6 (512 MiB)<br>35.2 (256 MiB)
|GDDR3
|256
|- 
!style="text-align:left"|GeForce 6800 Ultra Extreme
|May 4, 2004
|NV40 
|130
|AGP 8x
|256
|450
|1100 
|16:6:16:16
|7200
|7200
|7200
|675
|35.2 
|GDDR3
|256
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}

*<sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

====Features====
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=6 style="text-align:center;" | Features
|-
! OpenEXR HDR
! [[Scalable Link Interface]] (SLI)
! [[TurboCache]]
! [[Nvidia PureVideo|PureVideo]] WMV9 Decoding
|-
! style="text-align:left;"| GeForce 6100
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#FFB;vertical-align:middle;text-align:center; " class="table-partial"|Limited
|-
! style="text-align:left;"| GeForce 6150 SE
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#FFB;vertical-align:middle;text-align:center; " class="table-partial"|Driver-Side Only
| style="background:#FFB;vertical-align:middle;text-align:center; " class="table-partial"|Limited
|-
! style="text-align:left;"| GeForce 6150
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6150 LE
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#FFB;vertical-align:middle;text-align:center; " class="table-partial"|Driver-Side Only
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6200
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6500
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6600 LE
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (No SLI Connector)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6600
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (SLI Connector or PCI-E Interface)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6600 DDR2
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (SLI Connector or PCI-E Interface)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6600 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 6800 LE
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 6800 XT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (NV42 only)
|-
! style="text-align:left;"| GeForce 6800
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (NV41, NV42 only)
|-
! style="text-align:left;"| GeForce 6800 GTO
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 6800 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (NV42 only)
|-
! style="text-align:left;"| GeForce 6800 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 6800 Ultra
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
|}

===GeForce 7 (7xxx) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 7 Series|GeForce 7 Series]]</div>

* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1
* All models support Transparency [[Spatial anti-aliasing|AA]] (starting with version 91.47 of the ForceWare drivers)

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce 7025 + nForce 630a
|July 2007
|MCP68S
|110
|HyperTransport
|Up to 256 system RAM
|425
|533<br>800<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|2:1:2:2
|850
|850
|850
|106.25
|8.528<br>12.8<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR2
|128
|-
!style="text-align:left"|GeForce 7050 + nForce 630a
|July 2007
|MCP68V
|110
|HyperTransport
|Up to 256 system RAM
|425
|533<br>800<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|2:1:2:2
|850
|850
|850
|106.25
|8.528<br>12.8<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
|DDR2
|128
|- 
!style="text-align:left"|GeForce 7050PV + nForce 610i/630i
|July 2007
|MCP73QX
|90
|HyperTransport/FSB
|Up to 256 system RAM
|500
|667
|2:1:2:2
|1000
|1000
|1000
|125
|5.336
|DDR2
|64/128
|-
!style="text-align:left"|GeForce 7100 + nForce 630i
|July 2007
|MCP76
|90
|FSB
|Up to 256 system RAM
|600
|800
|2:1:2:2
|1200
|1200
|1200
|150
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7150 + nForce 630i
|July 2007
|MCP76
|90
|FSB
|Up to 256 system RAM
|630
|800
|2:1:2:2
|1260
|1260
|1260
|157.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7100 GS
|August 8, 2006
|NV44
|110
|PCI-E x16
|128<br>256
|350
|600
|4:3:4:2
|1400
|700
|1400
|262.5
|4.8
|DDR2
|64
|-
!style="text-align:left"|GeForce 7200 GS
|January 18, 2006
|G72
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|450
|800
|2:2:4:2
|1800
|900
|1800
|337.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 SE
|March 22, 2006
|G72
|90
|PCI-E x16
|128
|350
|666
|4:3:4:2
|1800
|900
|1800
|337.5
|5.328
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 LE
|March 22, 2006
|G72
|90
|PCI-E x16
|128
|350
|666
|8:5:8:4
|1800
|900
|1800
|337.5
|5.328
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 GS
|January 18, 2006
|G72
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|550
|800
|4:3:4:2
|2200
|1100
|2200
|412.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 GT
|May 15, 2006
|G73
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|650
|8:5:8:4
|2800
|1400
|2800
|437.5
|10.4
|DDR2
|128
|-
!style="text-align:left"|GeForce 7500 LE
|
|G72
|90
|AGP 8x<br>PCI-E x16
|64<br>128<br>256
|263<br>324
|550
|4:3:4:2
|900<br>1100
|900<br>1100
|2200
|412.5
|2.6<br>6.8
|DDR2
|32<br>64
|-
!style="text-align:left"|GeForce 7600 GS
|March 22, 2006 (PCI-E)<br>July 1, 2006 (AGP)
|G73
|90
|AGP 8x<br>PCI-E x16
|256
|400
|800
|12:5:12:8
|4800
|3200
|4800
|500
|12.8
|DDR2
|128
|-
!style="text-align:left"|GeForce 7600 GT
|March 9, 2006 (PCI-E)<br>July 15, 2006 (AGP)
|G73
|90
|AGP 8x<br>PCI-E x16
|256
|560
|1400
|12:5:12:8
|6720
|4480
|6720
|700
|22.4
|GDDR3
|128
|-
!style="text-align:left"|GeForce 7600 GT 80&nbsp;nm
|January 8, 2007
|G73-B1
|80
|AGP 8x<br>PCI-E x16
|256
|560
|1400
|12:5:12:8
|6720
|4480
|6720
|700
|22.4
|GDDR3
|128
|-
!style="text-align:left"|GeForce 7800 GS
|February 2, 2006
|G70
|110
|AGP 8x
|256
|375
|1200
|16:8:16:8
|6000
|3000
|6000
|562.5
|38.4
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7800 GT
|August 11, 2005
|G70
|110
|PCI-E x16
|256
|400
|1000
|20:7:20:16
|8000
|6400
|8000
|700
|32
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7800 GTX
|June 22, 2005 (256 MB)<br>November 14, 2005 (512 MB)
|G70
|110
|PCI-E x16
|256<br>512
|430 (256 MB)<br>550 (512 MB)
|1200 (256 MB)<br>1700 (512 MB)
|24:8:24:16
|10320 (256 MB)<br>13200 (512 MB)
|6880 (256 MB)<br>8800 (512 MB)
|10320 (256 MB)<br>13200 (512 MB)
|860 (256 MB)<br>1100 (512 MB)
|38.4 (256 MB)<br> 54.4 (512 MB)
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GS
|May 2006 (PCI-E)<br>April 2, 2007 (AGP)
|G71
|90
|AGP 8x<br>PCI-E x16
|256
|450
|1320
|20:7:20:16
|9000
|7200
|9000
|787.5
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GT
|March 9, 2006
|G71
|90
|PCI-E x16
|256
|450
|1320
|24:8:24:16
|10800
|7200
|10800
|900
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GTO
|October 1, 2006
|G71
|90
|PCI-E x16
|512
|650
|1320
|24:8:24:16
|15600
|10400
|15600
|1300
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GTX
|March 9, 2006
|G71
|90
|PCI-E x16
|512
|650
|1600
|24:8:24:16
|15600
|10400
|15600
|1300
|51.2
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GX2
|March 9, 2006
|G71 x2
|90
|PCI-E x16
|1024
|500
|1200
|24:8:24:16 x2
|24000
|16000
|24000
|2000
|76.8
|GDDR3
|512
|-
!style="text-align:left"|GeForce 7950 GT
|September 6, 2006 (PCI-E)<br>April 2, 2007 (AGP)
|G71
|90
|AGP 8x<br>PCI-E x16
|512
|550
|1400
|24:8:24:16
|13200
|8800
|13200
|1100
|44.8
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7950 GX2
|June 5, 2006
|G71 x2
|90
|PCI-E x16
|1024
|500
|1200
|24:8:24:16 x2
|24000
|16000
|24000
|2000
|76.8
|GDDR3
|512
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}
*<sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

====Features====
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=6 style="text-align:center;" | Features
|-
! Gamma-correct antialiasing
! 64-bit OpenEXR HDR
! Scalable Link Interface (SLI)
! TurboCache
! Dual Link DVI
|-
! style="text-align:left;"| GeForce 7100 GS
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 7200 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 7300 SE
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 7300 LE
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 7300 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)<br>(No SLI bridge)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 7300 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)<br>(No SLI bridge)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7600 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7600 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7600 GT (80&nbsp;nm)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7650 GS (80&nbsp;nm)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (Depending on OEM Design)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7800 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7800 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7800 GTX
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7800 GTX 512
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|One port
|-
! style="text-align:left;"| GeForce 7900 GS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|-
! style="text-align:left;"| GeForce 7900 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|-
! style="text-align:left;"| GeForce 7900 GTO
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|-
! style="text-align:left;"| GeForce 7900 GTX
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|-
! style="text-align:left;"| GeForce 7950 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (PCI-E only)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|-
! style="text-align:left;"| GeForce 7950 GX2
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Two ports
|}

===GeForce 8 (8xxx) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 8 Series|GeForce 8 Series]]</div>
All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 128-bit OpenEXR HDR
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup> Full G80 contains 32 texture address units and 64 texture filtering units unlike G92 which contains 64 texture address units and 64 texture filtering units

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory
! colspan=2 | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 8100 mGPU
| 2008
| MCP78
| 80
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1200
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 28.8
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| The block of decoding of HD-video PureVideo HD is disconnected
|-
! style="text-align:left;"| GeForce 8200 mGPU
| 2008
| MCP78
| 80
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1200
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 28.8
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| [[PureVideo]] 3 with VP3
|-
! style="text-align:left;"| GeForce 8300 mGPU
| 2008
| MCP78
| 80
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1500
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 36
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| [[PureVideo]] 3 with VP3
|-
! style="text-align:left;" | GeForce 8300 GS
| July 2007
| G86<br>G98
| 65
| 210
| 86
| PCIe 2.0 x16
| 128<br>512
| 8:8:4
| 450
| 900
| 800
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 22
| 40
| 0.55
| OEM only
|-
! style="text-align:left;" | GeForce 8400 GS
| June 15, 2007
| G86
| 80
| 210
| 127
| PCIe 1.0 x16<br>PCI
| 128<br>256<br>512
| 16:8:4
| 450
| 900
| 800
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 43
| 40
| 1.08
|
|-
! style="text-align:left;" | GeForce 8400 GS rev.2
| December 4, 2007
| G98
| 65
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 86
| PCIe 2.0 x16<br>PCIe x1<br>PCI
| 128<br>256<br>512
| 8:8:4
| 567
| 1400
| 800
| 2.268
| 4.536
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 33
| 25
| 1.32
|
|-
! style="text-align:left;" | GeForce 8400 GS rev.3
| April 2009
| GT218
| 40
| 260
| 57
| PCIe 2.0 x16
| 512<br>1024
| 8:4:4
| 520<br>589
| 1230
| 600 (1200)
| 
| 
| 4.8<br>9.6
| DDR3
| 32<br>64
| 10.1
| 3.3
| 30.5
| 
| 
|
|-
! style="text-align:left;"| GeForce 8500 GT
| April 17, 2007
| G86
| 80
| 210
| 127
| PCIe 1.0 x16<br>PCI
| 256<br>512<br>1024
| 16:8:4
| 450
| 900
| 400 (800)
| 1.8
| 3.6
| 12.8
| DDR2
| 128
| 10.0
| 3.3
| 43
| 45
| 0.96
|
|-
! style="text-align:left;"| GeForce 8600 GS
| April 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16
| 256<br>512
| 32:16:8
| 540
| 1180
| 800
| 4.32
| 8.64
| 12.8
| DDR2
| 128
| 10.0
| 3.3
| 113
| 47
| 2.40
| OEM only
|-
! style="text-align:left;"| GeForce 8600 GT
| April 17, 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16<br>PCI
| 256<br>512<br>1024
| 32:16:8
| 540
| 1188
| 800<br>1400
| 4.32
| 8.64
| 12.8<br>22.4
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 113
| 47
| 2.40
|
|-
! style="text-align:left;"| GeForce 8600 GTS
| April 17, 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16
| 256<br>512
| 32:16:8
| 675
| 1450
| 2000
| 5.4
| 10.8
| 32
| GDDR3
| 128
| 10.0
| 3.3
| 139
| 75
| 1.85
|
|-
! style="text-align:left;"| GeForce 8800 GS
| Jan 2008
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 384<br>768
| 96:48:12
| 550
| 1375
| 1600
| 6.6
| 26.4
| 38.4
| GDDR3
| 192
| 10.0
| 3.3
| 396
| 105
| 3.77
|
|-
! style="text-align:left;"| GeForce 8800 GTS (G80)
| February 12, 2007 (320) <br>November 8, 2006 (640)
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 320<br>640
| 96:24:20
| 500
| 1200
| 1600
| 10
| 24
| 64
| GDDR3
| 320
| 10.0
| 3.3
| 346
| 143
| 2.42
|
|-
! style="text-align:left;"| GeForce 8800 GTS 112 (G80)
| November 19, 2007
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 640
| 112:28<sup>2</sup>:20
| 500
| 1200
| 1600
| 10
| 24
| 64
| GDDR3
| 320
| 10.0
| 3.3
| 399
| 150
| 2.66
| only XFX, EVGA and BFG models, very short-lived
|-
! style="text-align:left;"| GeForce 8800 GT
| October 29, 2007 (512)<br>December 11, 2007 (256, 1024)
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 256<br>512<br>1024
| 112:56:16
| 600
| 1500
| 1400 (256)<br>1800 (512, 1024)
| 9.6
| 33.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 504
| 125
| 4.03
|
|-
! style="text-align:left;"| GeForce 8800 GTS (G92)
| December 11, 2007
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 512
| 128:64:16
| 650
| 1625
| 1940
| 10.4
| 41.6
| 62.1
| GDDR3
| 256
| 10.0
| 3.3
| 624
| 135
| 4.62
|
|-
! style="text-align:left;"| GeForce 8800 GTX
| November 8, 2006
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 768
| 128:32<sup>2</sup>:24
| 575
| 1350
| 1800
| 13.8
| 36.8
| 86.4
| GDDR3
| 384
| 10.0
| 3.3
| 518 (343)
| 155
| 3.34
|
|-
! style="text-align:left;"| GeForce 8800 Ultra
| May 2, 2007
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 768
| 128:32<sup>2</sup>:24
| 612
| 1500
| 2160
| 14.7
| 39.2
| 103.7
| GDDR3
| 384
| 10.0
| 3.3
| 576
| 171
| 3.37
|
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory min ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | Processing Power (GFLOPS)
! rowspan=2 | TDP (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory
! colspan=2 | API support (version)
|}

====Features====
*Compute Capability 1.1: has support for Atomic functions, which are used to write thread-safe programs.
*Compute Capability 1.2: for details see [[CUDA#Version_features_and_specifications|CUDA]]
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=9 style="text-align:center;" | Features
|-
! Scalable<br>Link<br>Interface<br>(SLI)
! 3-Way<br>SLI
! [[PureVideo]] HD<br>with VP1
! [[PureVideo]] 2 with VP2,
BSP Engine, and AES128 Engine
! [[PureVideo]] 3 with VP3,
BSP Engine, and AES128 Engine
! [[PureVideo]] 4 with VP4
! Compute<br>capability
|-
! style="text-align:left;"| GeForce 8300 GS (G86)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8400 GS Rev. 2 (G98)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8400 GS Rev. 3 (GT218)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.2
|-
! style="text-align:left;"| GeForce 8500 GT
| style="background:#bfd; color:black; vertical-align:middle; text-align:center; " class="table-yes2" | Yes (No SLI Bridge)
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8600 GT
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8600 GTS
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8800 GS (G92)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8800 GTS (G80)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|1.0
|-
! style="text-align:left;"| GeForce 8800 GTS Rev. 2 (G80)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|1.0
|-
! style="text-align:left;"| GeForce 8800 GT (G92)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8800 GTS (G92)
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|1.1
|-
! style="text-align:left;"| GeForce 8800 GTX
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|1.0
|-
! style="text-align:left;"| GeForce 8800 Ultra
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|1.0
|}

===GeForce 9 (9xxx) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 9 Series|GeForce 9 Series]]</div>

All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 128-bit OpenEXR HDR

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>[1]</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power [[Giga-|G]][[FLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 9300 mGPU
| October 2008
| MCP7A-S
| 65
| 282
| 162
| 1
| PCIe 2.0 x16
| Up to 512 from system memory
| 16:8:4
| 450
| 1200
| 800<br>1333
| 1.8
| 3.6
| 6.4/12.8<br>10.664/21.328
| DDR2<br>DDR3
| 64<br>128
| 10.0
| 3.3
| 57.6
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| based on 8400 GS
|-
! style="text-align:left;"| GeForce 9400 mGPU
| October 2008
| MCP7A-U
| 65
| 282
| 162
| 1
| PCIe 2.0 x16
| Up to 512 from system memory
| 16:8:4
| 580
| 1400
| 800<br>1333
| 2.32
| 4.64
| 6.4/12.8<br>10.664/21.328
| DDR2<br>DDR3
| 64<br>128
| 10.0
| 3.3
| 67.2
| 12
| 5.6
| based on 8400 GS
|-
! style="text-align:left;"| GeForce 9300 GE
| June 2008
| G98
| 65
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 86
| 1
| PCIe 2.0 x16
| 256
| 8:8:4
| 540
| 1300
| 1000
| 2.16
| 4.32
| 8
| DDR2
| 64
| 10.0
| 3.3
| 31.2
| ??
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;"| GeForce 9300 GS
| June 2008
| G98
| 65
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 86
| 1
| PCIe 2.0 x16
| 256
| 8:8:4
| 567
| 1400
| 1000
| 2.268
| 4.536
| 8
| DDR2
| 64
| 10.0
| 3.3
| 33.6
| ??
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;"| GeForce 9400 GT
| August 27, 2008
| G96a<br>G96b
| 65<br>55
| 314
| 144
| 1
| PCIe 2.0 x16<br>PCI
| 256<br>512<br>1024
| 16:8:4
| 550
| 1400
| 800<br>1600
| 2.2
| 4.4
| 12.8<br>25.6
| GDDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 67.2
| 50
| 1.34
|
|-
! style="text-align:left;"| GeForce 9500 GT
| July 29, 2008
| G96-300-C1
| 65<br>55
| 314
| 144
| 1
| PCIe 2.0 x16<br>PCI
| 256<br>512<br>1024
| 32:16:8
| 550
| 1400
| 1000<br>1600
| 4.4
| 8.8
| 16.0<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 134.4
| 50
| 2.69
|
|-
! style="text-align:left;"| GeForce 9600 GS
| July 29, 2008
| G94a
| 65
| 505
| 240
| 1
| PCIe 2.0 x16<br>PCI
| 768
| 48:24:12
| 500
| 1250
| 1000
| 6
| 12
| 24
| DDR2
| 192
| 10.0
| 3.3
| 180
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| OEM
|-
! style="text-align:left;"| GeForce 9600 GSO
| May 2008
| G92
| 65
| 754
| 324
| 1
| PCIe 2.0 x16
| 384<br>768<br>1536
| 96:48:12
| 550
| 1375
| 1600
| 6.6
| 26.4
| 38.4
| GDDR3
| 192
| 10.0
| 3.3
| 396
| 84
| 4.71
| 
|-
! style="text-align:left;"| GeForce 9600 GSO 512
| October 2008
| G94a<br>G94b
| 65<br>55
| 505
| 240<br>196?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1
| PCIe 2.0 x16
| 512
| 48:24:16
| 650
| 1625
| 1800
| 10.4
| 15.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 234
| 90
| 2.6
|
|-
! style="text-align:left;"| GeForce 9600 GT Green Edition
| 2009
| G94b
| 55
| 505
| 196?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1
| PCIe 2.0 x16
| 512<br>1024
| 64:32:16
| 600<br>625
| 1500<br>1625
| 1400/1800<br>1800<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 9.6<br>10.0
| 19.2<br>20.0
| 44.8/57.6<br>57.6<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| GDDR3
| 256
| 10.0
| 3.3
| 288<br>312
| 59
| 4.88<br>5.29
| Core Voltage - 1 volt
|-
! style="text-align:left;"| GeForce 9600 GT
| February 21, 2008
| G94-300-A1
| 65<br>55
| 505
| 240<br>196?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1
| PCIe 2.0 x16
| 512<br>1024
| 64:32:16
| 650
| 1625
| 1800
| 10.4
| 20.8
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 312
| 95
| 3.28
|
|-
! style="text-align:left;"| GeForce 9800 GT Green Edition
| 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 112:56:16
| 550
| 1375
| 1400<br>1600<br>1800
| 8.8
| 30.8
| 44.8<br>51.2<br>57.6
| GDDR3
| 256
| 10.0
| 3.3
| 462
| 75
| 6.16
| Core Voltage - 1 volt
|-
! style="text-align:left;"| GeForce 9800 GT
| July 2008
| G92a<br>G92b
| 65<br>55
| 754
| 324<br>260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 112:56:16
| 600
| 1500
| 1800
| 9.6
| 33.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 504
| 125<br>105
| 4.03<br>4.8
| 
|-
! style="text-align:left;"| GeForce 9800 GTX
| April 1, 2008
| G92
| 65
| 754
| 324
| 1
| PCIe 2.0 x16
| 512
| 128:64:16
| 675
| 1688
| 2200
| 10.8
| 43.2
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
| 648
| 140
| 4.63
|
|-
! style="text-align:left;"| GeForce 9800 GTX+
| July 16, 2008
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 738
| 1836
| 2200
| 11.808
| 47.232
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
| 705
| 141
| 5.0
|
|-
! style="text-align:left;"| GeForce 9800 GX2
| March 18, 2008
| G92
| 65
| 2x 754
| 2x 324
| 2
| PCIe 2.0 x16
| 2x 512
| 2x 128:64:16
| 600
| 1500
| 2000
| 2x 9.6
| 2x 38.4
| 2x 64.0
| GDDR3
| 2x 256
| 10.0
| 3.3
| 2x 576
| 197
| 5.85
|
|-
! style="text-align:center;"| Model
! Launch
! [[Codename]]
! Fab ([[Nanometer|nm]])
! Transistors (Million)
! Die Size (mm<sup>2</sup>)
! Die Count
! [[Computer bus|Bus]] [[I/O interface|interface]]
! Memory ([[Mebibyte|MiB]])
! Core config<sup>[1]</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! Processing Power [[Giga-|G]][[FLOPS]]
! [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! Comments
|}

====Features====
*Compute Capability: 1.1 has support for Atomic functions, which are used to write thread-safe programs.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=9 style="text-align:center;" | Features
|-
! Scalable Link Interface (SLI)
! [[PureVideo]] 2 with VP2,
BSP Engine, and AES128 Engine
! [[PureVideo]] 3 with VP3,
BSP Engine, and AES128 Engine
|-
! style="text-align:left;"| GeForce 9300 GE (G98)
| rowspan="7" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| rowspan="2" style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| rowspan="2" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce 9300 GS (G98)
|-
! style="text-align:left;"| GeForce 9400 GT
| rowspan="8" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| rowspan="8" style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce 9500 GT
|-
! style="text-align:left;"| GeForce 9600 GSO
|-
! style="text-align:left;"| GeForce 9600 GT
|-
! style="text-align:left;"| GeForce 9800 GT
|-
! style="text-align:left;"| GeForce 9800 GTX
| rowspan="2" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes<br/>3-way
|-
! style="text-align:left;"| GeForce 9800 GTX+
|-
! style="text-align:left;"| GeForce 9800 GX2
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|}

===GeForce 100 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 100 Series|GeForce 100 Series]]</div>

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab Process ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce G 100
| March 10, 2009
| G98
| 65
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 86
| 1
| PCIe 2.0 x16
| 512
| 8:8:4
| 567
| 1400
| 500
| 2.15
| 4.3
| 8.0
| DDR2
| 64
| 10.0
| 3.3
| 33.6
| 35
| 0.96
| OEM products
|-
! style="text-align:left;"| GeForce GT 120
| March 10, 2009
| G96b
| 55
| 314
| 121
| 1
| PCIe 2.0 x16
| 512
| 32:16:8
| 500
| 1400
| 800
| 4.4
| 8.8
| 16.0
| DDR2
| 128
| 10.0
| 3.3
| 134.4
| 50
| 2.69
| OEM products
|-
! style="text-align:left;"| GeForce GT 130
| March 10, 2009
| G94b
| 55
| 505
| 196?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1
| PCIe 2.0 x16
| 1536
| 48:24:12
| 500
| 1250
| 500
| 6
| 12
| 24.0
| DDR2
| 192
| 10.0
| 3.3
| 180
| 75
| 2.4
| OEM products
|-
! style="text-align:left;"| GeForce GT 140
| March 10, 2009
| G94b
| 55
| 505
| 196?
| 1
| PCIe 2.0 x16
| 512 
1024
| 64:32:16
| 650
| 1625
| 1800
| 10.4
| 20.8
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 312
| 105
| 2.97
| OEM products
|-
! style="text-align:left;"| GeForce GTS 150
| March 10, 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 1024
| 128:64:16
| 738
| 1836
| 1000
| 11.808
| 47.232
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 705
| 141
| 5.0
| OEM products
|}

===GeForce 200 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 200 Series|GeForce 200 Series]]</div>

All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 240-bit OpenEXR HDR
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory Configuration
! colspan=2 | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 205
| November 26, 2009
| GT218
| 40
| 260
| 57
| 1
| PCIe 2.0 x16
| 512
| 8:4:4
| 589
| 1402
| 1000
| 2.356
| 2.356
| 8
| DDR2
| 64
| 10.1
| 3.3
| 33.4
| 30.5
| 1.06
| OEM only
|-
! style="text-align:left;"| GeForce 210
| October 12, 2009
| GT218
| 40
| 260
| 57
| 1
| PCIe 2.0 x16<br>PCIe x1<br>PCI
| 512<br>1024
| 16:8:4
| 520<br>589
| 1230<br>1402
| 1000–1600
| 2.356
| 4.712
| 4.0<br>8.0<br>12.8
| DDR2<br>DDR3
| 32<br>64
| 10.1
| 3.3
| 67.296
| 30.5
| 2.21
|
|-
! style="text-align:left;"| GeForce GT 220
| October 12, 2009
| GT216
| 40
| 486
| 100
| 1
| PCIe 2.0 x16
| 512<br>1024
| 48:16:8
| 615(OEM)<br>625
| 1335(OEM)<br>1360
| 1000<br>1580
| 5
| 10
| 16.0<br>25.3
| DDR2<br>DDR3
| 128
| 10.1
| 3.3
| 192(OEM)<br>196
| 58
| 3.31(OEM)<br>3.38
|
|-
! style="text-align:left;"| GeForce GT 230 v.1
| 2009
| G94b
| 55
| 505
| 196?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1
| PCIe 2.0 x16
| 512<br>1024
| 48:24:16
| 650
| 1625
| 1800
| 10.4
| 15.6
| 57.6
| GDDR3
| 256
| 10
| 3.3
| 234
| 75
| 3.12
| OEM only
|-
! style="text-align:left;"| GeForce GT 230 v.2
| 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 1536
| 96:48:12
| 500
| 1242
| 1000
| 6
| 24
| 24
| DDR2
| 192
| 10
| 3.3
| 357.69
| 75
| 4.77
| OEM only
|-
! style="text-align:left;"| GeForce GT 240
| November 17, 2009
| GT215
| 40
| 727
| 139
| 1
| PCIe 2.0 x16
| 512<br>1024
| 96:32:8
| 550
| 1340
| 1800<br>2000<br>3400(GDDR5)
| 4.4
| 17.6
| 28.8(OEM)<br>32<br>54.4(GDDR5)
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 385.9
| 69
| 5.59
|
|-
! style="text-align:left;"| GeForce GTS 240
| Q4 2009
| G92a<br>G92b
| 65<br>55
| 754
| 324<br>260
| 1
| PCIe 2.0 x16
| 1024
| 112:56:16
| 675
| 1620
| 2200
| 10.8
| 37.8
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
|554.32
| 120
| 4.62
| OEM only
|-
! style="text-align:left;"| GeForce GTS 250 Green
| 2009
| G92b
| 65<br>55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 702
| 1512
| 2000
| 11.2
| 44.9
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 581
| 130
| 4.47
| 
|-
! style="text-align:left;"| GeForce GTS 250
| March 3, 2009
| G92-428-B1
| 65<br>55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 738
| 1836
| 2000<br>2200
| 11.808
| 47.232
| 64.0<br>70.4
| GDDR3
| 256
| 10.0
| 3.3
| 705.024
| 150
| 4.86
| Some cards are rebranded GeForce 9800 GTX+
|-
! style="text-align:left;"| GeForce GTX 260
| June 16, 2008
| GT200-100-A2
| 65
| 1400
| 576
| 1
| PCIe 2.0 x16
| 896
| 192:64:28
| 576
| 1242
| 1998
| 16.128
| 36.864
| 111.9
| GDDR3
| 448
| 10.0
| 3.3
| 715.392
| 202
| 3.54
| Replaced by GTX 260 Core 216
|-
! style="text-align:left;"| GeForce GTX 260 Core 216
| September 16, 2008
| GT200-103-A2<br>GT200-105-B3
| 65<br>55
| 1400
| 576<br>470
| 1
| PCIe 2.0 x16
| 896 (1792)
| 216:72:28
| 576
| 1242
| 1998
| 16.128
| 41.472
| 111.9
| GDDR3
| 448
| 10.0
| 3.3
| 804.816<br>874.8
| 182<br>171
| 4.42<br>4.71
|
|-
! style="text-align:left;"| GeForce GTX 275
| April 9, 2009
| GT200-400-B3
| 55
| 1400
| 470
| 1
| PCIe 2.0 x16
| 896
| 240:80:28
| 633
| 1404
| 2268
| 17.724
| 50.6
| 127.0
| GDDR3
| 448
| 10.0
| 3.3
| 1010.880
| 219
| 4.62
|Effectively one-half of the GTX 295
|-
! style="text-align:left;"| GeForce GTX 280
| June 17, 2008
| GT200-300-A2
| 65
| 1400
| 576
| 1
| PCIe 2.0 x16
| 1024
| 240:80:32
| 602
| 1296
| 2214
| 19.264
| 48.16
| 141.7
| GDDR3
| 512
| 10.0
| 3.3
| 933.120
| 236
| 3.95
| Replaced by GTX 285
|-
! style="text-align:left;"| GeForce GTX 285
| January 15, 2009
| GT200-350-B3
| 55
| 1400
| 470
| 1
| PCIe 2.0 x16
| 1024 (2048*)
| 240:80:32
| 648
| 1476
| 2484
| 20.736
| 51.84
| 159.0
| GDDR3
| 512
| 10.0
| 3.3
| 1062.72
| 204
| 5.24
| Palit and EVGA launched 2GB versions. EVGA GTX285 Classified can support 4-way SLI
|-
! style="text-align:left;"| GeForce GTX 295
| January 8, 2009
| GT200-400-B3
| 55
| '''2x''' 1400
| '''2x''' 470
| 2
| PCIe 2.0 x16
| '''2x''' 896
| '''2x''' 240:80:28
| 576
| 1242
| 1998
| '''2x''' 16.128
| '''2x''' 46.08
| '''2x''' 111.9
| GDDR3
| '''2x''' 448
| 10.0
| 3.3
| 1788.480
| 289
| 6.19
| Dual PCB models were phased out in favor of a single PCB model with 2 GPUs
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config <sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | GFLOPS (MADD+MUL)
! rowspan=2 | TDP (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory Configuration
! colspan=2 | API support (version)
|}

====Features====
Compute Capability: 1.1 (G92 [GTS250] GPU)
<br>Compute Capability: 1.2 (GT215, GT216, GT218 GPUs)
<br>Compute Capability: 1.3 has [[Double precision floating-point format|double precision]] support for use in [[GPGPU]] applications. (GT200a/b GPUs only)

{| class="wikitable" style="font-size: 85%; text-alig: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=8 style="text-align:center;" | Features
|-
! Scalable Link Interface (SLI)
! [[PureVideo]] 2 with VP2
Engine: (BSP and 240 AES)
! [[PureVideo]] 4 with VP4 Engine
|-
! style="text-align:left;"| GeForce 210
| colspan="1" rowspan="3" style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| colspan="1" rowspan="3" style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
| colspan="3" rowspan="3" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
|-
! style="text-align:left;"| GeForce GT 220
|-
! style="text-align:left;"| GeForce GT 240
|-
! style="text-align:left;"| GeForce GTS 250
| rowspan="7" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes<br/>3-Way (4-way for EVGA 285 Classified)
| colspan="1" rowspan="8" style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes
| colspan="1" rowspan="8" style="background:#F99;vertical-align:middle;text-align:center;" class="table-no"|No
|-
! style="text-align:left;"| GeForce GTX 260
|-
! style="text-align:left;"| GeForce GTX 260 Core 216
|-
! style="text-align:left;"| GeForce GTX 260 Core 216 (55&nbsp;nm)
|-
! style="text-align:left;"| GeForce GTX 275
|-
! style="text-align:left;"| GeForce GTX 280
|-
! style="text-align:left;"| GeForce GTX 285
|-
! style="text-align:left;"| GeForce GTX 295
| style="background:#9F9;vertical-align:middle;text-align:center;" class="table-yes"|Yes<br/>
|}

===GeForce 300 Series===

<div class="rellink relarticle mainarticle">Main article: [[GeForce 300 Series|GeForce 300 Series]]</div>

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the chip of G80/GT200 architecture contains 8 SPs and 2 SFUs.  Each SP can fulfill up to two single precision operations MAD per clock. Each SFU can fulfill up to four operations SF per clock (these units can also handle single-precision floating-point multiplications per clock). The approximate ratio of operations MAD to operations SF is equal 2:1. The theoretical SP + SFU performance in single-precision floating point operations [''FLOPS<sub>sp + sfu</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following formula: ''FLOPS<sub>sp+sfu</sub>'' ˜ f × n × 3.   Alternative formula:   ''FLOPS<sub>sp+sfu</sub>'' ˜ f × m × ( 8 SPs * 2 (MAD) + 4 * 2 SFUs ). [''m''] - SM count.
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, MAD - ADD+MUL.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 |Processing Power GFLOPS<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 310
| November 27, 2009
| GT218
| 40
| 260
| 57
| 1
| PCIe 2.0 x16
| 512
| 16:8:4
| 589
| 1402
| 1000
| 2.356
| 4.712
| 8
| DDR2
| 64
| 10.1
| 3.3
| 67.296
| 30.5
| 2.21
| OEM Card, similar to Geforce 210
|-
! style="text-align:left;"| GeForce 315
| February, 2010
| GT216
| 40
| 486
| 100
| 1
| PCIe 2.0 x16
| 512
| 48:16:8
| 475
| 1100
| 1580
| 3.8
| 7.6
| 12.6
| DDR3
| 64
| 10.1
| 3.3
| 158.4
| 33
| 4.8
| OEM Card, similar to Geforce GT220
|-
! style="text-align:left;"| GeForce GT 320
| February, 2010
| GT215
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 1024
| 72:24:8
| 540
| 1302
| 1580
| 4.32
| 12.96
| 25.3
| GDDR3
| 128
| 10.1
| 3.3
| 281.23
| 43
| 6.54
| OEM Card
|-
! style="text-align:left;"| GeForce GT 330
| February, 2010
| GT215-301-A3
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 1024<br>1536<br>2048
| 96:48?:8?<br>96:48?:12?<br>112:56?:16?<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 500<br>550<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1250<br>1340<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 1000 (DDR2)<br>1600 (GDDR3)
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 24<br>32<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| DDR2<br>GDDR3
| 128<br>192<br>256
| 10
| 3.3
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 75
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Specifications vary depending on OEM, similar to GT230 v2.
|-
! style="text-align:left;"| GeForce GT 340
| February, 2010
| GT215
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 512<br>1024
| 96:32:8
| 550
| 1340
| 3400
| 4.4
| 17.6
| 54.4
| GDDR5
| 128
| 10.1
| 3.3
| 385.9
| 69
| 5.59
| OEM Card, similar to GT240
|}

===GeForce 400 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 400 Series|GeForce 400 Series]]</div>
'''Please take note''': Memory bandwidths mentioned in the following table refer nVidia reference designs. Actual bandwidth can be higher or ''lower'' depending on the manufacturer of the graphic board.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF100 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF104/106/108 architecture contains 48 SPs and 8 SFUs. Each SP can fulfill up to two single precision operations FMA per clock. Each SFU can fulfill up to four operations SF per clock. The approximate ratio of operations FMA to operations SF is equal: for GF100 4:1 and for GF104/106/108 3:1. The theoretical shader performance in single-precision floating point operations(FMA) [''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>'' ˜ f × n × 2. Alternative formula: for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × m × (32 SPs × 2(FMA)) and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × m × (48 SPs × 2(FMA)). [''m''] - SM count. Total Processing Power: for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × m ×(32 SPs × 2(FMA) + 4 × 4 SFUs) and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × m × (48 SPs × 2(FMA) + 4 × 8 SFUs) or for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × n × 2.5 and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × n × 8 / 3. where:
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, [[Fused multiply–add|FMA]] - Fused MUL+ADD.
* <sup>3</sup> Each SM in the GF100 contains 4 texture filtering units for every texture address unit. The complete GF100 die contains 64 texture address units and 256 texture filtering units. Each SM in the GF104/106/108 architecture contains 8 texture filtering units for every texture address unit but has doubled both addressing and filtering units. The complete GF104 die also contains 64 texture address units and 512 texture filtering units despite the halved SM count, the complete GF106 die contains 32 texture address units and 256 texture filtering units and the complete GF108 die contains 16 texture address units and 128 texture filtering units.
* <sup>4</sup> Note that while GTX 460's TDP is comparable to that of AMD's HD5000 Series, GF100-based cards (GTX 480/470/465) are rated much lower but pull significantlly more power, e.g. GTX 480 with 250W TDP consumes More power than an HD 5970 with 297W TDP.
* <sup>6</sup> The 400 Series is the only non-OEM family since GeForce 8 not to include an official dual-GPU system. However, on March 18, 2011, [[EVGA Corporation|EVGA]] released the first single-PCB card with dual 460's on board. The card came with 2048 MB of memory at 3600&nbsp;MHz and 672 shader processors at 1400&nbsp;MHz and was offered at the MSRP of $429.
* <sup>7</sup> The GeForce 405 card is a remarked GeForce 310 which itself is a remarked GeForce 210.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>5</sup>
|-
! style="text-align:left;"| GeForce 405 (OEM)<sup>7</sup>
| September 16, 2011
| GT216<br>GT218
| 40
| 486<br>260
| 100<br>57
| 1
| PCIe 2.0 x16
| 512<br>1024
| 1
| 48:16:8<br>16:8:4
| 475<br>589
| 1100<br>1402
| 800<br>790
| 3.8<br>2.36
| 7.6<br>4.71
| 12.6
| DDR3
| 64
| 10.1
| 3.1
| 1.1
| 105.6<br>44.86
| 30.5
| 
| OEM
|-
! style="text-align:left;"| GeForce GT 420 (OEM)
| September 3, 2010
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 2048
| 1
| 48:4:4
| 700
| 1400
| 1800
| 2.8
| 2.8
| 28.8
| GDDR3
| 128
| 11
| 4.4
| 1.1
| 134.4
| 50
| 2.69
| OEM
|-
! style="text-align:left;"| GeForce GT 430 (OEM)
| October 11, 2010
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 2048
| 2
| 96:16:4
| 700
| 1400
| 1600<br>1800
| 2.8
| 11.2
| 25.6<br>28.8
| GDDR3
| 128
| 11
| 4.4
| 1.1
| 268.8
| 60
| 4.48
| OEM
|-
! style="text-align:left;" rowspan=2| GeForce GT 430
|rowspan=2| October 11, 2010
|rowspan=2| GF108
|rowspan=2| 40
|rowspan=2| 585
|rowspan=2| 116
|rowspan=2| 1
|rowspan=2| PCIe 2.0 x16<br>PCI
|rowspan=2| 512<br>1024
|rowspan=2| 2
|rowspan=2| 96:16:4
|rowspan=2| 700
|rowspan=2| 1400
| 1800
|rowspan=2| 2.8
|rowspan=2| 11.2
| 28.8
|rowspan=2| GDDR3
| 128
|rowspan=2| 11
|rowspan=2| 4.4
|rowspan=2| 1.1
|rowspan=2| 268.8
|rowspan=2| 49
|rowspan=2| 5.49
|rowspan=2| $79
|-
| 1300
| 10.4
| 64
|-
! style="text-align:left;"| GeForce GT 440
| February 1, 2011
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 512<br>1024<br>2048
| 2
| 96:16:4
| 810
| 1620
| 1800<br>3200
| 3.24
| 12.96
| 28.8<br>51.2
| GDDR3<br>GDDR5
| 128
| 11
| 4.4
| 1.1
| 311.04
| 65
| 4.78
| $100
|-
! style="text-align:left;"| GeForce GT 440 (OEM)
| October 11, 2010
| GF106
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:24
| 594
| 1189
| 1800
| 14.26
| 14.26
| 43.2
| GDDR3
| 192
| 11
| 4.4
| 1.1
| 342.43
| 56
| 6.11
| OEM
|-
! style="text-align:left;"| GeForce GTS 450 (OEM)
| October 11, 2010
| GF106
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1024<br>1536
| 3
| 144:24:24
| 790
| 1580
| 4000
| 18.96
| 18.96
| 96
| GDDR5
| 192
| 11
| 4.4
| 1.1
| 455.04
| 106
| 4.29
| OEM
|-
! style="text-align:left;"| GeForce GTS 450
| September 13, 2010<br>March 15, 2011
| GF106-250<br>GF116-200
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 512<br>1024
| 4
| 192:32:16
| 783
| 1566
| 3608
| 12.53
| 25.06
| 57.73
| GDDR5
| 128
| 11
| 4.4
| 1.1
| 601.34
| 106
| 5.67
| $129
|-
! style="text-align:left;"| GeForce GTX 460 SE
| November 15, 2010
| GF104-225-A1
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:32
| 650
| 1300
| 3400
| 20.8
| 31.2
| 108.8
| GDDR5
| 256
| 11
| 4.4
| 1.1
| 748.8
| 150
| 4.99
| $160
|-
! style="text-align:left;"| GeForce GTX 460 (OEM)
| October 11, 2010
| GF104
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 7
| 336:56:32
| 650
| 1300
| 3400
| 20.8
| 36.4
| 108.8
| GDDR5
| 256
| 11
| 4.4
| 1.1
| 873.6
| 150
| 5.82
| OEM
|-
! style="text-align:left;" rowspan=2| GeForce GTX 460<sup>6</sup>
|rowspan=2| July 12, 2010
|rowspan=2| GF104-300-KB-A1
|rowspan=2| 40
|rowspan=2| 1950
|rowspan=2| 332
|rowspan=2| 1
|rowspan=2| PCIe 2.0 x16
| 768
|rowspan=2| 7
| 336:56:24
|rowspan=2| 675
|rowspan=2| 1350
|rowspan=2| 3600
| 16.2
|rowspan=2| 37.8
| 86.4
|rowspan=2| GDDR5
| 192
|rowspan=2| 11
|rowspan=2| 4.4
|rowspan=2| 1.1
|rowspan=2| 907.2
|150
| 6.05
| $199
|-
|1024<br>2048
|336:56:32
|21.6
|115.2
|256
|160
|5.67
|$229
|-
! style="text-align:left;"| GeForce GTX 460 v2
| September 24, 2011
| GF114
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 7
| 336:56:24
| 778
| 1556
| 4008
| 18.67
| 43.57
| 96.2
| GDDR5
| 192
| 11
| 4.4
| 1.1
| 1045.6
| 160
| 6.54
| $199
|-
! style="text-align:left;"| GeForce GTX 465
| May 31, 2010
| GF100
| 40
| 3000
| 529
| 1
| PCIe 2.0 x16
| 1024
| 11
| 352:44:32
| 607
| 1215
| 3206
| 19.42
| 26.71
| 102.6
| GDDR5
| 256
| 11
| 4.4
| 1.1
| 855.36
| 200<sup>4</sup>
| 4.28
| $279
|-
! style="text-align:left;"| GeForce GTX 470
| March 26, 2010
| GF100
| 40
| 3000
| 529
| 1
| PCIe 2.0 x16
| 1280
| 14
| 448:56:40
| 607
| 1215
| 3348
| 24.28
| 34
| 133.9
| GDDR5
| 320
| 11
| 4.4
| 1.1
| 1088.64
| 215<sup>4</sup>
| 5.06
| $349
|-
! style="text-align:left;"| GeForce GTX 480
| March 26, 2010
| GF100
| 40
| 3000
| 529
| 1
| PCIe 2.0 x16
| 1536
| 15
| 480:60:48
| 700
| 1401
| 3696
| 33.60
| 42
| 177.4
| GDDR5
| 384
| 11
| 4.4
| 1.1
| 1344.96
| 250<sup>4</sup>
| 5.38
| $499
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|}

===GeForce 500 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 500 Series|GeForce 500 Series]]</div>
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF110 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF114/116/118/119 architecture contains 48 SPs and 8 SFUs.  Each SP can fulfill up to two single precision operations FMA per clock.  Each SFU can fulfill up to four SF operations per clock. The approximate ratio of operations FMA to operations SF is equal 4:1. The theoretical shader performance in single-precision floating point operations(FMA)[''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>'' ˜ f × n × 2. Alternative formula: ''FLOPS<sub>sp</sub>'' ˜ f × m × (32 SPs × 2(FMA)). [''m''] - SM count. Total Processing Power: ''FLOPS<sub>sp</sub>'' ˜ f × m × (32 SPs × 2(FMA) + 4 × 4 SFUs) or ''FLOPS<sub>sp</sub>'' ˜ f × n × 2.5.
* <sup>3</sup> Each SM in the GF110 contains 4 texture filtering units for every texture address unit. The complete GF110 die contains 64 texture address units and 256 texture filtering units. Each SM in the GF114/116/118 architecture contains 8 texture filtering units for every texture address unit but has doubled both addressing and filtering units.
* <sup>4</sup> Internally referred to as GF104B
* <sup>5</sup> Internally referred to as GF100B
* <sup>6</sup> Similar to previous generation, GTX 580 and most likely future GTX 570, while reflecting its improvement over GF100, still have lower rated TDP and higher power consumption, e.g. GTX580 (243W TDP) is slightly less power hungry than GTX 480 (250W TDP). This is managed by clock throttling through drivers when a dedicated power hungry application is identified that could breach card TDP. Application name changing will disable throttling and enable full power consumption, which in some cases could be close to that of GTX480.
* <sup>7</sup> Some companies have announced that they will be offering the GTX580 with 3GB VRAM.
* <sup>9</sup> 1024 MB RAM on 192-bit bus assemble with 4 * (128 MB) + 2 * (256 MB).

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>6</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>8</sup>
|-
! style="text-align:left;"| GeForce 510
| September 29, 2011
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 1
| 48:8:4
| 523
| 1046
| 1800
| 2.1
| 4.4
| 14.4
| DDR3
| 64
| 11
| 4.4
| 1.1
| 100.4
| 25
| 4.02
| OEM
|-
! style="text-align:left;"| GeForce GT 520
| April 12, 2011
| GF119
| 40
| ?
| 79
| 1
| PCIe 2.0 x16<br>PCIe 2.0 x1<br>PCI
| 1024<br>2048
| 1
| 48:8:4
| 810
| 1620
| 1800
| 3.25
| 6.5
| 14.4
| DDR3
| 64
| 11
| 4.4
| 1.1
| 155.5
| 29
| 5.36
| $59
|-
! style="text-align:left;"| GeForce GT 530
| May 14, 2011
| GF108? / GF118<sup class="Template-Fact" style="white-space:nowrap;">&#91;<i>[[Wikipedia:Citation needed|<span title="This claim needs references to reliable sources. (September 2012)">citation needed</span>]]</i>&#93;</sup>
| 40
| ~585
| ~116
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 2
| 96:16:4
| 700
| 1400
| 1800
| 2.8
| 11.2
| 28.8
| DDR3
| 128
| 11
| 4.4
| 1.1
| 268.8
| 50
| 5.38
| OEM
|-
! style="text-align:left;"| GeForce GT 545 DDR3
| May 14, 2011
| GF116
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:16
| 720
| 1440
| 1800
| 11.52
| 17.28
| 43
| DDR3
| 192
| 11
| 4.4
| 1.1
| 415.07
| 70
| 5.93
| $149
|-
! style="text-align:left;"| GeForce GT 545 GDDR5
| May 14, 2011
| GF116
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1024
| 3
| 144:24:16
| 870
| 1740
| 1998
| 13.92
| 20.88
| 64
| GDDR5
| 128
| 11
| 4.4
| 1.1
| 501.12
| 105
| 4.77
| OEM
|-
! style="text-align:left;"| GeForce GTX 550 Ti
| March 15, 2011
| GF116-400
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1024<br>3072
| 4
| 192:32:24
| 900
| 1800
| 4104
| 21.6
| 28.8
| 98.5
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.4
| 1.1
| 691.2
| 116
| 5.96
| $149
|-
! style="text-align:left;"| GeForce GTX 555
| 14 May 2011
| GF114
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 736
| 1472
| 3828
| 17.6
| 35.3
| 91.9
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.4
| 1.1
| 847.9
| 150
| 5.65
| OEM
|-
! style="text-align:left;"| GeForce GTX 560 SE
| N/A
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 736
| 1472
| 3828
| 17.7
| 35.3
| 91.9
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.4
| 1.1
| 847.8
| 150
| 5.65
| OEM
|-
! style="text-align:left;"| GeForce GTX 560
| May 17, 2011
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024 2048
| 7
| 336:56:32
| 810
| 1620
| 4008
| 25.92
| 45.36
| 128.1
| GDDR5
| 256
| 11
| 4.4
| 1.1
| 1088.6
| 150
| 7.26
| $199
|-
! style="text-align:left;"| GeForce GTX 560 Ti
| January 25, 2011
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 8
| 384:64:32
| 822
| 1645
| 4008
| 26.3
| 52.61
| 128.26
| GDDR5
| 256
| 11
| 4.4
| 1.1
| 1263.4
| 170
| 7.43
| $249
|-
! style="text-align:left;"| GeForce GTX 560 Ti OEM
| May 30, 2011
| GF110<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280<br>2560
| 11
| 352:44:40
| 732
| 1464
| 3800
| 29.28
| 32.21
| 152
| GDDR5
| 320
| 11
| 4.4
| 1.1
| 1030.7
| 210<sup>6</sup>
| 4.91
| OEM
|-
! style="text-align:left;"| GeForce GTX 560 Ti 448 Cores Limited Edition
| November 29, 2011
| GF110-270-A1<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280 
| 14
| 448:56:40
| 732
| 1464
| 3800
| 29.28
| 40.99
| 152
| GDDR5
| 320
| 11
| 4.4
| 1.1
| 1311.7
| 210<sup>6</sup>
| 6.25
| $289
|-
! style="text-align:left;"| GeForce GTX 570
| December 7, 2010
| GF110-275-A1<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280
2560
| 15
| 480:60:40
| 732
| 1464
| 3800
| 29.28
| 43.92
| 152
| GDDR5
| 320
| 11
| 4.4
| 1.1
| 1405.4
| 219<sup>6</sup>
| 6.41
| $349
|-
! style="text-align:left;"| GeForce GTX 580
| November 9, 2010
| GF110-375-A1<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1536<br>3072<sup>7</sup>
| 16
| 512:64:48
| 772
| 1544
| 4008
| 37.05
| 49.41
| 192.384
| GDDR5
| 384
| 11
| 4.4
| 1.1
| 1581.1
| 244<sup>6</sup>
| 6.48
| $499
|-
! style="text-align:left;"| GeForce GTX 590
| March 24, 2011
| '''2x'''
GF110-351-A1
| 40
| '''2x'''
3000
| '''2x'''
520
| 2
| PCIe 2.0 x16
| '''2x'''
1536
| 2×16
| '''2x'''
512:64:48
| 607
| 1215
| 3414
| 2×29.14
| 2×38.85
| 2×163.87
| GDDR5
| 2×384
| 11
| 4.4
| 1.1
| 2488.3
| 365
| 6.82
| $699
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>8</sup>
|}

===GeForce 600 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 600 Series |GeForce 600 Series ]]</div>
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> The GeForce 605 (OEM) card is a rebranded GeForce 510.
* <sup>3</sup> The GeForce GT 610 card is a rebranded GeForce GT 520.
* <sup>4</sup> The GeForce GT 620 (OEM) card is a rebranded GeForce GT 520.
* <sup>5</sup> The GeForce GT 620 card is a rebranded GeForce GT 530.
* <sup>6</sup> This revision of GeForce GT 630 (DDR3) card is a rebranded GeForce GT 440 (DDR3).
* <sup>7</sup> The GeForce GT 630 (GDDR5) card is a rebranded GeForce GT 440 (GDDR5).
* <sup>8</sup> The GeForce GT 640 (OEM) card is a rebranded GeForce GT 545 (DDR3).
* <sup>9</sup> The GeForce GT 645 (OEM) card is a rebranded GeForce GTX 560 SE.

{| class="wikitable" style="font-size: 80%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1</sup>
! colspan=5 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|-
! style="text-align:left;"| GeForce 605<sup>2</sup>
| April 3, 2012
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 512
1024
| 1
| 48:8:4
| 523
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1046
| 1798
| 2.1
| 4.4
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 100.4
| 25
| 4.02
| OEM
|-
! style="text-align:left;"| GeForce GT 610 <sup>3</sup>
| May 15, 2012
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16, PCIe x1, PCI
| 512<br>1024<br>2048
| 1
| 48:8:4
| 810
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1620
| 1000<br>1800
| 3.24
| 6.5
| 8<br>14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 155.5
| 29
| 5.36
| Retail
|-
! style="text-align:left;"| GeForce GT 620 <sup>4</sup>
| April 3, 2012
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16, PCI
| 512<br>1024
| 1
| 48:8:4
| 810
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1620
| 1798
| 3.24
| 6.5
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 155.5
| 30
| 5.18
| OEM
|-
! style="text-align:left;"| GeForce GT 620<sup>5</sup>
| May 15, 2012
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024<br>2048
| 2
| 96:16:4
| 700
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1400
| 1000–1800
| 2.8
| 11.2
| 8–14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 268.8
| 49
| 5.49
| Retail
|-
! style="text-align:left;"| GeForce GT 625
| February 19, 2013
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 512
1024
| 1
| 48:8:4
| 810
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
|style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1620
| 1798
| 3.24
| 6.5
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 155.5
| 30
| 5.18
| OEM
|-
! style="text-align:left;"| GeForce GT 630
| April 24, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 1
| 192:16:16<br>(1 SMX)
| 875
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 875
| 891<br>(1782)
| 14
| 14
| 28.5
| DDR3
| 128
| 11.0
| 4.4
| 1.1
| 336
| 50
| 6.72
| OEM
|-
! style="text-align:left;"| GeForce GT 630 (DDR3)<sup>6</sup>
| May 15, 2012
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024<br>2048<br>4096
| 2
| 96:16:4
| 810
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1620
| 1000–1800
| 3.2
| 13
| 16–28.8
| DDR3
| 128
| 11.0
| 4.4
| 1.1
| 311
| 65
| 4.79
| Retail
|-
! style="text-align:left;"| GeForce GT 630 (GDDR5)<sup>7</sup>
| May 15, 2012
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024
| 2
| 96:16:4
| 810
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1620
| 3200
| 3.2
| 13
| 51.2
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 311
| 65
| 4.79
| Retail
|-
! style="text-align:left;"| GeForce GT 630 (Rev. 2)
| May 29, 2013
| GK208
| 28
| 
| 79
| 1
| PCIe 2.0 x8
| 1024<br>2048
| 2
| 384:16:8<br>(2 SMX)
| 902
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 902
| 1800
| 7.22
| 14.44
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 1.1
| 692.7
| 25
| 27.68
| 
|-
! style="text-align:left;"| GeForce GT 635
| February 19, 2013
| GK208
| 28
| 
| 79
| 1
| PCIe 2.0 x8
| 1024<br>2048
| 1
| 192:16:16<br>(1 SMX)
| 875
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 875
| 1782
| 14
| 14
| 28.5
| DDR3
| 128
| 11.0
| 4.4
| 1.1
| 336
| 50
| 6.72
| OEM
|-
! style="text-align:left;"| GeForce GT 640<sup>8</sup>
| April 24, 2012
| GF116
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:24
| 720
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1440
| 1782
| 17.3
| 17.3
| 42.8
| DDR3
| 192
| 11.0
| 4.4
| 1.1
| 414.7
| 75
| 5.53
| OEM
|-
! style="text-align:left;"| GeForce GT 640 (DDR3)
| April 24, 2012
| GK107-301-A2
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16<br>(2 SMX)
| 797
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 797
| 891<br>(1782)
| 12.8
| 25.5
| 28.5
| DDR3
| 128
| 11.0
| 4.4
| 1.1
| 612.1
| 50
| 12.24
| OEM
|-
! style="text-align:left;"| GeForce GT 640 (DDR3)
| June 5, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 2
| 384:32:16<br>(2 SMX)
| 900
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 900
| 891<br>(1782)
| 14.4
| 28.8
| 28.5
| DDR3
| 128
| 11.0
| 4.4
| 1.1
| 691.2
| 65
| 10.63
| $100
|-
! style="text-align:left;"| GeForce GT 640 (GDDR5)
| April 24, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16<br>(2 SMX)
| 950
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 950
| 1250<br>(5000)
| 15.2
| 30.4
| 80
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 729.6
| 75
| 9.73
| OEM
|-
! style="text-align:left;"| GeForce GT 640 Rev. 2
| May 29, 2013
| GK208
| 28
| 
| 79
| 1
| PCIe 2.0 x8
| 1024
| 2
| 384:16:8<br>(2 SMX)
| 1046
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1046
| 5010
| 8.37
| 16.7
| 40.1
| GDDR5
| 64
| 11.0
| 4.4
| 1.1
| 803.3
| 49
| 16.39
| 
|-
! style="text-align:left;"| GeForce GT 645<sup>9</sup>
| April 24, 2012
| GF114-400-A1
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 776
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1552
| 1914
| 18.6
| 37.3
| 91.9
| GDDR5
| 192
| 11.0
| 4.4
| 1.1
| 894
| 140
| 6.39
| OEM
|-
! style="text-align:left;"| GeForce GTX 645
| April 22, 2013
| GK106
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024
| 3
| 576:48:16<br>(3 SMX)
| 823.5
| 888.5
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 823
| 1000<br>(4000)
| 14.16
| 39.5
| 64
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 948.1
| 64
| 14.81
| OEM
|-
! style="text-align:left;"| GeForce GTX 650
| September 13, 2012
| GK107-450-A2
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16<br>(2 SMX)
| 1058
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 1058
| 1250<br>(5000)
| 16.9
| 33.8
| 80
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 812.54
| 64
| 12.7
| $110
|-
! style="text-align:left;"| GeForce GTX 650 Ti
| October 9, 2012
| GK106-220-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 4
| 768:64:16<br>(4 SMX)
| 928
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 928
| 1350<br>(5400)
| 14.8
| 59.4
| 86.4
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 1425.41
| 110
| 12.92
| $150 (130)
|-
! style="text-align:left;"| GeForce GTX 650 Ti Boost
| March 26, 2013
| GK106-240-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 4
| 768:64:24<br>(4 SMX)
| 980
| 1032
| style="background: #ececec; color: grey; vertical-align: middle; text-align: center; " class="table-na" | <small>N/A</small>
| 980
| 1502<br>(6008)
| 23.5
| 62.7
| 144.2
| GDDR5
| 192
| 11.0
| 4.4
| 1.1
| 1505.28
| 134
| 11.23
| $170 (150)
|-
! style="text-align:left;"| GeForce GTX 660
| September 13, 2012
| GK106-400-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 2048<br />3072
| 5
| 960:80:24<br>(5 SMX)
| 980
| 1032
| 1084
| 980
| 1502<br>(6008)
| 23.5
| 78.4
| 144.2
| GDDR5
| 192
| 11.0
| 4.4
| 1.1
| 1881.6
| 140
| 13.44
| $230 (180)
|-
! style="text-align:left;"| GeForce GTX 660 (OEM)
| August 22, 2012
| GK104-200-KD-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 1536<br />2048
| 6
| 1152:96:24<br>1152:96:32<br>(6 SMX)
| 823.5
| 888.5
| 899
| 823
| 1450<br>(5800)
| 19.8
| 79
| 134
| GDDR5
| 192<br>256
| 11.0
| 4.4
| 1.1
| 2108.6
| 130
| 16.22
| OEM
|-
! style="text-align:left;"| GeForce GTX 660 Ti
| August 16, 2012
| GK104-300-KD-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br />3072
| 7
| 1344:112:24<br>(7 SMX)
| 915
| 980
| 1058
| 915
| 1502<br>(6008)
| 22.0
| 102.5
| 144.2
| GDDR5
| 192
| 11.0
| 4.4
| 1.1
| 2459.52
| 150
| 16.40
| $300
|-
! style="text-align:left;"| GeForce GTX 670
| May 10, 2012
| GK104-325-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 7
| 1344:112:32<br>(7 SMX)
| 915
| 980
| 1084
| 915
| 1502<br>(6008)
| 29.3
| 102.5
| 192.256
| GDDR5
| 256
| 11.0
| 4.4
| 1.1
| 2459.52
| 170
| 14.47
| $400
|-
! style="text-align:left;"| GeForce GTX 680
| March 22, 2012
| GK104-400-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 8
| 1536:128:32<br>(8 SMX)
| 1006
| 1058
| 1110
| 1006
| 1502<br>(6008)
| 32.2
| 128.8
| 192.256
| GDDR5
| 256
| 11.0
| 4.4
| 1.1
| 3090.43
| 195
| 15.85
| $500
|-
! style="text-align:left;"| GeForce GTX 690
| April 29, 2012
| 2× GK104-355-A2
| 28
| 2× 3540
| 2× 294 
| 2
| PCIe 3.0 x16
| 2× 2048
| 2× 8
| 2× 1536:128:32<br>(2× 8 SMX)
| 915
| 1019
| 1058
| 915
| 1502<br>(6008)
| 2× 29.28
| 2× 117.12
| 2× 192.256
| GDDR5
| 2× 256
| 11.0
| 4.4
| 1.1
| 2× 2810.88
| 300
| 18.74
| $1000
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1</sup>
! colspan=5 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|}

===GeForce 700 Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 700 Series |GeForce 700 Series ]]</div>
The GeForce 700 series for desktop architecture.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Max Boost depends on ASIC quality. For example some GTX Titan with over 80% ASIC quality can hit 1019&nbsp;MHz by default, lower ASIC quality will be 1006&nbsp;MHz or 993&nbsp;MHz.
* <sup>3</sup> Kepler support 11.1 features with 11_0 feature level through the DirectX 11.1 API, however Nvidia did not enable four non-gaming features in Hardware in Kepler (for 11_1).

{| class="wikitable" style="font-size: 80%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | SMX count
! rowspan=2 | Core config <sup>1</sup>
! colspan=4 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! colspan=2 style="text-align:center;" | Processing Power (peak) <br> [[GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! colspan=2 style="text-align:center;" | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Base ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost <sup>2</sup>([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]<sup>3</sup>
! [[OpenGL]]
! [[OpenCL]]
! Single Precision
! Double Precision
! Single Precision
! Double Precision
|-
! style="text-align:left;" | GeForce GTX 750
| February 18, 2014
| GM107
| 28
| 1870
| 148
| 1
| PCIe 3.0 x16
| 1024
| 4
| 512:32:16<br>(4 SMM)
| 1020
| 1085
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 1250<br>(5000)
| 16.3
| 32.6
| 80
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 1044
| 32.6
| 55
| 19
| 0.59
| $119
|-
! style="text-align:left;" | GeForce GTX 750 Ti
| February 18, 2014
| GM107
| 28
| 1870
| 148
| 1
| PCIe 3.0 x16
| 2048
| 5
| 640:40:16<br>(5 SMM)
| 1020
| 1085
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 1350<br />(5400)
| 16.3
| 40.8
| 88
| GDDR5
| 128
| 11.0
| 4.4
| 1.1
| 1306
| 40.8
| 60
| 21.8
| 0.68
| $149
|-
! style="text-align:left;" | GeForce GTX 760 192-bit
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| GK104
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 1536<br>3072
| 6
| 1152:96:24<br>(6 SMX)
| 823
| 888
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| 1450<br>(5800)
| 19.8
| 79
| 134
| GDDR5
| 192
| 11.0
| 4.4
| 1.1
| 1896
| 79
| 130
| 14.6
| 0.60
| OEM
|-
! style="text-align:left;" | GeForce GTX 760
| June 25, 2013
| GK104-225-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048
| 6
| 1152:96:32<br>(6 SMX)
| 980
| 1033
| 1124
| 1502<br>(6008)
| 31.4
| 94
| 192.3
| GDDR5
| 256
| 11.0
| 4.4
| 1.1
| 2257
| 94
| 170
| 13.3
| 0.55
| $249
|-
! style="text-align:left;" | GeForce GTX 760 Ti
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| GK104
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048
| 7
| 1344:112:32<br>(7 SMX)
| 915
| 980
| 1084
| 1502<br>(6008)
| 29.3
| 102.5
| 192.3
| GDDR5
| 256
| 11.0
| 4.4
| 1.1
| 2460
| 103
| 170
| 14.5
| 0.60
| OEM
|-
! style="text-align:left;" | GeForce GTX 770
| May 30, 2013
| GK104-425-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048
4096
| 8
| 1536:128:32<br>(8 SMX)
| 1046
| 1085
| 1130
| 1753<br>(7012)
| 33.5
| 134
| 224
| GDDR5
| 256
| 11.0
| 4.4
| 1.1
| 3213
| 134
| 230
| 14.0
| 0.58
| $399 ($329)
|-
! style="text-align:left;" | GeForce GTX 780
| May 23, 2013
| GK110-300-A1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 3072
6144
| 12
| 2304:192:48<br>(12 SMX)
| 863
| 900
| 1002
| 1502<br>(6008)
| 41.4
| 160.5
| 288.4
| GDDR5
| 384
| 11.0
| 4.4
| 1.1
| 3977
| 166
| 250
| 15.9
| 0.66
| $649 ($499)
|-
! style="text-align:left;" | GeForce GTX 780 Ti
| Nov 7, 2013
| GK110-425-B1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 3072
| 15
| 2880:240:48<br>(15 SMX)
| 875
| 928
| 1020
| 1750<br>(7000)
| 42.0
| 210.2
| 336.4
| GDDR5
| 384 
| 11.0
| 4.4
| 1.1
| 5046
| 210
| 250
| 20.2
| 0.84
| $699
|-
! style="text-align:left;"| GeForce <br> GTX Titan
| February 21, 2013
| GK110-400-A1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 6144
| 14
| 2688:224:48<br>(14 SMX)
| 837
| 876
| 993
| 1502<br>(6008)
| 40.2
| 187.5
| 288.4
| GDDR5
| 384
| 11.0
| 4.4
| 1.1
| 4500
| 1300-1500
| 250
| 18
| 5.2-6
| $999
|-
! style="text-align:left;"| GeForce GTX <br> Titan Black
| February 18, 2014
| GK110-430
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 6144
| 15
| 2880:240:48<br>(15 SMX)
| 889
| 980
| (?)
| 1750<br>(7000)
| 40.2
| 187.5
| 336.4
| GDDR5
| 384
| 11.0
| 4.4
| 1.1
| 5000
| 1700
| 250
| 20
| 6.8
| $999
|-
! style="text-align:left;" | GeForce GTX <br> Titan Z
| March 25, 2014
| 2× GK110
| 28
| 2× 7080
| 2×561
| 2
| PCIe 3.0 x16
| 2× 6144
| 2× 15
| 2× 2880:240:48<br>(2× 15 SMX)
| 
| 
| 
| 
| 
| 
| 
| GDDR5
| 2×
| 11.0
| 4.4
| 1.1
| 
| 
| 
| 
| 
| $2999
|}

==Comparison table: Mobile GPUs==

===GeForce2 Go Series===

* All models are manufactured with a 180&nbsp;nm manufacturing process
* All models support [[DirectX]] 7.0 and [[OpenGL]] 1.2

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce2 Go 100 
|February 6, 2001
|NV11M
|AGP 4x
|8, 16
|125
|332
|2:0:4:2
|250
|250
|500
|0
|1.328
|DDR
|32
|-
!style="text-align:left"|GeForce2 Go 
|November 11, 2000
|NV11M
|AGP 4x
|16, 32
|143
|166<br>332 
|2:0:4:2
|286
|286
|572
|0
|2.656
|SDR<br>DDR
|128<br>64
|-
!style="text-align:left"|GeForce2 Go 200
|February 6, 2001
|NV11M
|AGP 4x
|16, 32
|143
|332 
|2:0:4:2
|286
|286
|572
|0
|2.656
|DDR
|64
|}

*<sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce4 Go Series===

* All models are manufactured with a 150&nbsp;nm manufacturing process

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application Programming Interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]] 
|-
!style="text-align:left"|GeForce4 Go 410 
|February 6, 2002
|NV17M
|AGP 8X
|16
|200
|200
|2:0:4:2
|400
|400
|800
|0
|1.6
|SDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 420 
|February 6, 2002
|NV17M
|AGP 8X
|32
|200
|400
|2:0:4:2
|400
|400
|800
|0
|3.2
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 440 
|February 6, 2002
|NV17M
|AGP 8X
|64
|220
|440
|2:0:4:2
|440
|440
|880
|0
|7.04
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 460 
|October 14, 2002
|NV17M
|AGP 8X
|64
|250
|500
|2:0:4:2
|500
|500
|1000
|0
|8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 488 
|
|NV18M
|AGP 8X
|64
|300
|550
|2:0:4:2
|600
|600
|1200
|0
|8.8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 4200 
|November 14, 2002
|NV28M
|AGP 8X
|64
|200
|400
|4:2:8:4
|800
|800
|1600
|100
|6.4
|DDR
|64
|8.1
|1.3
|}

*<sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce FX Go 5 (Go 5xxx) Series===
The GeForce FX Go 5 Series for notebooks architecture.
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
* <sup>**</sup> GeForce FX Series has limited OpenGL 2.1 support(with the last Windows XP driver released for it, 175.19).
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=3 | Model
! rowspan=3 | Launch
! rowspan=3 | [[Code name]]
! rowspan=3 | Fab ([[Nanometer|nm]])
! rowspan=3 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=3 | Memory ([[Mebibyte|MiB]])
! rowspan=3 | Core clock ([[Hertz|MHz]])
! rowspan=3 | Memory clock ([[Hertz|MHz]])
! rowspan=3 | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=3 | [[Thermal Design Power|TDP]] (watts)
! rowspan=3 | Features
|-
! rowspan=2 | Pixel ([[Pixel|GP]]/s)
! rowspan=2 | Texture ([[Texel (graphics)|GT]]/s)
! rowspan=2 | Bandwidth ([[Gigabyte|GB]]/s)
! rowspan=2 | Bus type
! rowspan=2 | Bus width ([[bit]])
! rowspan=2 | [[DirectX]]
! colspan=2 | [[OpenGL]]
|-
! Hardware
! Drivers (Software)
|-
! style="text-align:left;" | GeForce FX Go 5100<sup>*</sup>
| March 2003
| NV34M
| 150
| AGP x8
| 64
| 200
| 400
| 1:2:2:2 *:4:4:4
| 0.8
| 0.8
| 3.2
| DDR
| 64
| 9.0
| 1.5
| 2.1**
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;" | GeForce FX Go 5200<sup>*</sup>
| March 2003
| NV34M
| 150
| AGP x8
| 32<br>64
| 300
| 600
| 1:2:2:2 *:4:4:4
| 1.2
| 1.2
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;" | GeForce FX Go 5600<sup>*</sup>
| March 2003
| NV31M
| 130
| AGP x8
| 32
| 350
| 600
| 1:2:2:2 *:4:4:4
| 1.4
| 1.4
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;" | GeForce FX Go 5650<sup>*</sup>
| March 2003
| NV31M
| 130
| AGP x8
| 32
| 350
| 600
| 1:2:2:2 *:4:4:4
| 1.4
| 1.4
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;" | GeForce FX Go 5700<sup>*</sup>
| February 1, 2005
| NV36M
| 130
| AGP x8
| 32
| 450
| 550
| 3:2:2:2 *:4:4:4
| 1.8
| 1.8
| 8.8
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|}

===GeForce Go 6 (Go 6xxx) Series===

* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce Go 6100 + nForce Go 430
|style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|C51M
|110
|HyperTransport
|Up to 128 MB system
|425
|System Memory
|2:1:2:1
|850
|425
|850
|106.25
|System Memory
|DDR2
|64/128
|-
!style="text-align:left"|GeForce Go 6150 + nForce Go 430
|style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|C51M
|110
|HyperTransport
|Up to 128 MB system
|425
|System Memory
|2:1:2:1
|850
|425
|850
|106.25
|System Memory
|DDR2
|64/128
|-
!style="text-align:left"|GeForce Go 6200
|style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|NV44M
|110
|PCI-E x16
|16
|300
|600
|4:3:4:2
|1200
|600
|1200
|225
|2.4 
|DDR
|32
|-
!style="text-align:left"|GeForce Go 6400
|style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|NV44M
|110
|PCI-E x16
|16
|400
|700
|4:3:4:2
|1600
|800
|1600
|250
|5.6
|DDR
|64
|-
!style="text-align:left"|GeForce Go 6600
|style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|NV43M
|110
|PCI-E x16
|128
|300
|700
|8:3:8:4
|3000
|1500
|3000
|281.25
|11.2
|DDR
|128
|-
!style="text-align:left"|GeForce Go 6800
|November 8, 2004
|NV41M
|130
|PCI-E x16
|128
|300
|700<br>1100
|12:5:12::12
|3000
|1500
|3000
|375
|22.4<br>35.2
|DDR, DDR2<br>DDR3
|256
|-
!style="text-align:left"|GeForce Go 6800 Ultra
|February 24, 2005
|NV41M
|130
|PCI-E x16
|256
|450
|700<br>1100
|12:5:12::12
|5400
|3600
|5400
|562.5
|22.4<br>35.2
|DDR, DDR2<br>DDR3
|256
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce Go 7 (Go 7xxx) Series===
The GeForce Go 7 Series for notebooks architecture.
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup> Graphics card supports [[TurboCache]], memory size entries in bold indicate total memory (VRAM + System RAM), otherwise entries are VRAM only
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Features
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
!style="text-align:left;" | GeForce 7000M
| February 1, 2006
| MCP67MV
| 90
| [[HyperTransport|Hyper Transport]]
| Up to 256 from system memory
| 350
| System Memory
| 1:2:2:2
| 0.7
| 0.7
| System Memory
| DDR2
| 64/128
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
!style="text-align:left;" | GeForce 7150M
| February 1, 2006
| MCP67M
| 90
| [[HyperTransport|Hyper Transport]]
| Up to 256 from system memory
| 425
| System Memory
| 1:2:2:2
| 0.85
| 0.85
| System Memory
| DDR2
| 64/128
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
|
|-
! style="text-align:left;" | GeForce Go 7200<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 64
| 450
| 700
| 3:4:4:1
| 0.45
| 1.8
| 2.8
| GDDR3
| 32
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7300<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 128, 256, '''512'''
| 350
| 700
| 3:4:4:2
| 0.7
| 1.4
| 5.60
| GDDR3
| 64
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7400<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 64, '''256'''
| 450
| 900
| 3:4:4:2
| 0.9
| 1.8
| 7.20
| GDDR3
| 64
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7600
| Mar 2006
| G73M
| 90
| PCIe x16
| 256, 512
| 450
| 1000
| 5:8:8:8
| 3.6
| 3.6
| 16
| GDDR3
| 128
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7600 GT
| 2006
| G73M
| 90
| PCIe x16
| 256
| 500
| 1200
| 5:12:12:8
| 4
| 6
| 19.2
| GDDR3
| 128
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7700
| 2006
| G73-N-B1
| 80
| PCIe x16
| 512
| 450
| 1000
| 5:12:12:8
| 3.6
| 5.4
| 16
| GDDR3
| 128
| 9.0c
| 2.1
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7800
| March 3, 2006
| G70M
| 110
| PCIe x16
| 256
| 400
| 1100
| 6:16:16:8
| 3.2
| 6.4
| 35.2
| GDDR3
| 256
| 9.0c
| 2.1
| 35
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7800 GTX
| Oct 2005
| G70M
| 110
| PCIe x16
| 256
| 400
| 1100
| 8:24:24:16
| 6.4
| 9.6
| 35.2
| GDDR3
| 256
| 9.0c
| 2.1
| 65
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7900 GS
| Apr 2006
| G71M
| 90
| PCIe x16
| 256
| 375
| 1000
| 7:20:20:16
| 6
| 7.5
| 32.0
| GDDR3
| 256
| 9.0c
| 2.1
| 20
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7900 GTX
| Apr 2006
| G71M
| 90
| PCIe x16
| 256/512
| 500
| 1200
| 8:24:24:16
| 8
| 12
| 38.4
| GDDR3
| 256
| 9.0c
| 2.1
| 45
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7950 GTX
| Oct 2006
| G71M
| 90
| PCIe x16
| 512
| 575
| 1400
| 8:24:24:16
| 9.2
| 13.8
| 44.8
| GDDR3
| 256
| 9.0c
| 2.1
| 45
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|}

===GeForce 8M (8xxxM) Series===
The GeForce 8M Series for notebooks architecture.
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power [[GigaFLOPS|GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 8200M G 
| June 2008
| MCP77MV, MCP79MVL
| 80
| Integrated (PCIe 2.0 x16)
| Up to 256 from system memory
| 8:8:4
| 400
| 800
| 800<br>1066<br>(system memory)
| 1.6
| 3.2
| 12.8<br>17.056
| DDR2<br>DDR3
| 128
| 10.0
| 3.3
| 19.2
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| [[PureVideo]] HD with VP3, Full H.264 / VC-1 / MPEG-2 HW Decode
|-
! style="text-align:left;" | GeForce 8400M G
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 128 / 256
| 8:8:4
| 400
| 800
| 800
| 1.6
| 3.2
| 6.4
| DDR2 / GDDR3
| 64
| 10.0
| 3.3
| 19.2
| 10
| 1.92
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8400M GS
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 128 / 256
| 16:8:4
| 400
| 800
| 800
| 1.6
| 3.2
| 6.4
| DDR2 / GDDR3
| 64
| 10.0
| 3.3
| 38.4
| 11
| 3.49
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8400M GT
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 256 / 512
| 16:8:4
| 450
| 900
| 1200
| 1.8
| 3.6
| 19.2
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 43.2
| 14
| 3.09
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8600M GS
| May 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 16:8:4
| 600
| 1200
| 1400
| 2.4
| 4.8
| 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 57.6
| 20
| 2.88
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8600M GT
| May 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 32:16:8
| 475
| 950
| 800 / 1400
| 3.8
| 7.6
| 12.8 / 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 91.2
| 20
| 4.56
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8700M GT
| June 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 32:16:8
| 625
| 1250
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 120
| 29
| 4.14
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8800M GTS
| November 2007
| NB8P(G92)
| 65
| PCIe 2.0 x16
| 512
| 64:32:16
| 500
| 1250
| 1600
| 8
| 16
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 240
| 50
| 4.8
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8800M GTX
| November 2007
| NB8P(G92)
| 65
| PCIe 2.0 x16
| 512
| 96:48:16
| 500
| 1250
| 1600
| 8
| 24
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 360
| 65
| 5.54
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|}

===GeForce 9M (9xxxM) Series===
The GeForce 9M Series for notebooks architecture.
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 9100M G <br>mGPU
| 2008
| MCP77MH, MCP79MH
| 65
| Integrated <br>(PCIe 2.0 x16)
| Up to 256 from system memory
| 8:8:4
| 450
| 1100
| 1066<br>(system memory)
| 1.8
| 3.6
| 17.056
| DDR3
| 128
| 10.0
| 3.3
| 26.4
| 12
| 2.2
| Similar to 8400M G
|-
! style="text-align:left;" | GeForce 9200M GS
| 2008
| NB9M-GE(G98)
| 65
| PCIe 2.0 x16
| 256
| 8:8:4
| 550
| 1300
| 1400
| 2.2
| 4.4
| 11.2
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 31.2
| 13
| 2.4
|
|-
! style="text-align:left;" | GeForce 9300M G
| 2008
| NB9M-GE(G86)
| 80
| PCIe 2.0 x16
| 256/512
| 16:8:4
| 400
| 800
| 1200
| 1.6
| 3.2
| 9.6
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 38.4
| 13
| 2.95
| 
|-
! style="text-align:left;" | GeForce 9300M GS
| 2008
| NB9M-GE(G98)
| 65
| PCIe 2.0 x16
| 256/512
| 8:8:4
| 550
| 1400
| 1400
| 2.2
| 4.4
| 11.2
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 33.6
| 13
| 2.58
|
|-
! style="text-align:left;" | GeForce 9400M G
| October 15, 2008
| MCP79MX
| 65
| Integrated(PCIe 2.0 x16)
| Up to 256 from system memory
| 16:8:4
| 450
| 1100
| 800<br>1066<br>(system memory)
| 1.8
| 3.6
| 12.8<br>17.056
| DDR2<br>DDR3
| 128
| 10.0
| 3.3
| 54
| 12
| 4.5
| PureVideo HD with VP3. Known as the GeForce 9400M in Apple systems and [[Nvidia ION]] based systems
|-
! style="text-align:left;" | GeForce 9500M G
| 2008
| NB9P(G96)
| 65
| PCIe 2.0 x16
| 512
| 16:8:8
| 500
| 1250
| 1600
| 4
| 4
| 25.6
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 60
| 20
| 3.0
|
|-
! style="text-align:left;" | GeForce 9500M GS
| 2008
| NB9P-GV(G96)
| 80
| PCIe x16
| 512
| 32:16:8
| 475
| 950
| 1400
| 3.8
| 7.6
| 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 91.2
| 20
| 4.56
|Rebranded 8600M GT
|-
! style="text-align:left;" | GeForce 9600M GS
| 2008
| NB9P-GE2(G96)
| 65
| PCIe 2.0 x16
| 1024
| 32:16:8
| 430
| 1075
| 800<br>1600
| 3.44
| 6.88
| 12.8<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 103.2
| 20
| 5.16
|
|-
! style="text-align:left;" | GeForce 9600M GT
| 2008
| NB9P-GS(G96)
| 65
| PCIe 2.0 x16
| 512/1024
| 32:16:8
| 500
| 1250
| 1600
| 4
| 8
| 25.6
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 120
| 23
| 5.22
|
|-
! style="text-align:left;" | GeForce 9650M GS
| 2008
| NB9P-GS1(G84)
| 80
| PCIe 2.0 x16
| 512
| 32:16:8
| 625
| 1250
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 120
| 29
| 4.14
|Rebranded 8700M GT
|-
! style="text-align:left;" | GeForce 9650M GT
| 2008
| NB9P-GT(G96)
| 65/55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 550
| 1325
| 1600
| 4.4
| 8.8
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 127.2
| 23
| 5.53
|
|-
! style="text-align:left;" | GeForce 9700M GT
| July 29, 2008
| NB9E-GE(G96)
| 65
| PCIe x16
| 512
| 32:16:8
| 625
| 1550
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 148.8
| 45
| 3.31
|
|-
! style="text-align:left;" | GeForce 9700M GTS
| July 29, 2008
| NB9E-GS(G94)
| 65
| PCIe 2.0 x16
| 512
| 48:24:16
| 530
| 1325
| 1600
| 8.48
| 12.7
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 190.8
| 60
| 3.18
|
|-
! style="text-align:left;" | GeForce 9800M GS
| 2008
| NB9E-GT(G94)
| 65
| PCIe 2.0 x16
| 512
| 64:32:16
| 530
| 1325
| 1600
| 8.48
| 16.96
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 254
| 60
| 4.23
|Down Clocked 9800M GTS Via Firmware
|-
! style="text-align:left;" | GeForce 9800M GTS
| July 29, 2008
| NB9E-GT(G94)
| 65/55
| PCIe 2.0 x16
| 512 / 1024
| 64:32:16
| 600
| 1500
| 1600
| 9.6
| 19.2
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 288
| 75
| 3.84
|
|-
! style="text-align:left;" | GeForce 9800M GT
| July 29, 2008
| NB9E-GT2(G92)
| 65/55
| PCIe 2.0 x16
| 512
| 96:48:16
| 500
| 1250
| 1600
| 8
| 24
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 360
| 65
| 5.54
|Rebranded 8800M GTX
|-
! style="text-align:left;" | GeForce 9800M GTX
| July 29, 2008
| NB9E-GTX(G92)
| 65
| PCIe 2.0 x16
| 1024
| 112:56:16
| 500
| 1250
| 1600
| 8
| 28
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 420
| 75
| 5.6
|
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | GFLOPS (MADD/MUL)
! rowspan=2 | [[Thermal Design Power|TDP]] (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
|}

===GeForce 100M (1xxM) Series===
The GeForce 100M Series for notebooks architecture. (103M, 105M, 110M, 130M are rebranded GPU i.e. using the same GPU cores of previous generation, 9M, with promised optimisation on other features)
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce G 102M
| January 8, 2009
| MCP79XT
| 65
| Integrated<br>(PCIe 1.0 x16)
| Up to 512 from system memory
| 16:8:4
| 450?
| 1000
| 800<br>(system memory)
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 48
| 14
| 3.43
| PureVideo HD, CUDA, Hybrid SLI, based on GeForce 9400M G
|-
! style="text-align:left;" | GeForce G 103M
| January 1, 2009
| N10M-GE2(G98)
| 65
| PCIe 2.0 x16
| 512
| 8:8:4
| 640
| 1600
| 1000
| 2.56
| 5.12
| 8
| DDR2
| 64
| 10.0
| 3.3
| 38
| 14
| 2.71
| PureVideo HD, CUDA, Hybrid SLI, comparable to the GeForce 9300M GS
|-
! style="text-align:left;" | GeForce G 105M
| January 8, 2009
| N10M-GE1(G98)
| 65
| PCIe 2.0 x16
| 512
| 8:8:4
| 640
| 1600
| 1000<br>1400
| 2.56
| 5.12
| 8<br>11
| GDDR2<br>GDDR3
| 64
| 10.0
| 3.3
| 38
| 14
| 2.71
| PureVideo HD, CUDA, Hybrid SLI, comparable to the GeForce 9300M GS
|-
! style="text-align:left;" | GeForce G 110M
| January 8, 2009
| N10M-GE1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 16:8:4
| 400
| 1000
| 1000<br>1400
| 1.6
| 3.2
| 8<br>11
| DDR2<br>GDDR3
| 64
| 10.0
| 3.3
| 48
| 14
| 3.43
| PureVideo HD, CUDA, Hybrid SLI
|-
! style="text-align:left;" | GeForce GT 120M
| February 11, 2009
| N10P-GV1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 500
| 1250
| 1000
| 4
| 8
| 16
| DDR2
| 128
| 10.0
| 3.3
| 110
| 23
| 4.78
| PureVideo HD, CUDA, Hybrid SLI, Comparable to the 9500M GT and 9600M GT DDR2 (500/1250/400)
|-
! style="text-align:left;" | GeForce GT 130M
| January 8, 2009
| N10P-GE1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 600
| 1500
| 1000<br>1600
| 4.8
| 9.6
| 16<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 144
| 23
| 6.26
| PureVideo HD, CUDA, Hybrid SLI, comparable to the 9650M GT
|-
! style="text-align:left;" | GeForce GTS 150M
| March 3, 2009
| N10E-GE1(G94b)
| 55
| PCIe 2.0 x16
| 1024
| 64:32:16
| 400
| 1000
| 1600
| 6.4
| 12.8
| 51.2
| GDDR3
| 256

| 10.0
| 3.3
| 192
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| style="background: #E4E4E4; color: black; vertical-align: middle; text-align: center; " class="unknown table-unknown"|Unknown
| PureVideo HD, CUDA, Hybrid SLI
|-
! style="text-align:left;" | GeForce GTS 160M
| March 3, 2009
| N10E-GS1(G94b)
| 55
| PCIe 2.0 x16
| 1024
| 64:32:16
| 600
| 1500
| 1600
| 9.6
| 19.2
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 288
| 60
| 4.8
| PureVideo HD, CUDA, Hybrid SLI
|}

===GeForce 200M (2xxM) Series===
The GeForce 200M Series is a graphics processor architecture for notebooks.
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce G210M
| June 15, 2009
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 625
| 1500
| 1600
| 2.5
| 5
| 12.8
| GDDR3
| 64
| 10.1
| 3.3
| 72
| 14
| 5.14
| Lower clocked versions of the GT218 core is also known as [[Nvidia Ion|Nvidia ION 2]]
|-
! style="text-align:left;" | GeForce GT 220M
| 2009
| G96b
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 500
| 1250
| 1000<br>1600
| 4
| 8
| 16<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 120
| 14
| 8.57
| rebranded 9600M GT @55&nbsp;nm node shrink
|-
! style="text-align:left;" | GeForce GT 230M
| June 15, 2009
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 500
| 1100
| 1600
| 4
| 8
| 25.6
| GDDR3
| 128
| 10.1
| 3.3
| 158
| 23
| 6.87
|
|-
! style="text-align:left;" | GeForce GT 240M
| June 15, 2009
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 550
| 1210
| 1600
| 4.4
| 8.8
| 25.6
| GDDR3
| 128
| 10.1
| 3.3
| 174
| 23
| 7.57
|
|-
! style="text-align:left;" | GeForce GTS 250M
| June 15, 2009
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 500
| 1250
| 3200
| 4
| 16
| 51.2
| GDDR5
| 128
| 10.1
| 3.3
| 360
| 28
| 12.86
|
|-
! style="text-align:left;" | GeForce GTS 260M
| June 15, 2009
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 550
| 1375
| 3600
| 4.4
| 17.6
| 57.6
| GDDR5
| 128
| 10.1
| 3.3
| 396
| 38
| 10.42
|
|-
! style="text-align:left;" | GeForce GTX 260M
| March 3, 2009
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 112:56:16
| 550
| 1375
| 1900
| 8.8
| 30.8
| 60.8
| GDDR3
| 256
| 10.0
| 3.3
| 462
| 65
| 7.11
|
|-
! style="text-align:left;" | GeForce GTX 280M
| March 3, 2009
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 128:64:16
| 585
| 1463
| 1900
| 9.36
| 37.44
| 60.8
| GDDR3
| 256
| 10.0
| 3.3
| 562
| 75
| 7.49
|
|-
! style="text-align:left;" | GeForce GTX 285M
| February, 2010
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 128:64:16
| 600
| 1500
| 2000
| 9.6
| 38.4
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 576
| 75
| 7.68
| Higher Clocked Version of GTX280M with new memory
|}

===GeForce 300M (3xxM) Series===
The GeForce 300M Series for notebooks architecture.
*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the chip of G80/GT200 architecture contains 8 SPs and 2 SFUs.  Each SP can fulfill up to two single precision operations MAD per clock. Each SFU can fulfill up to four operations SF per clock (these units can also handle single-precision floating-point multiplications per clock). The approximate ratio of operations MAD to operations SF is equal 2:1. The theoretical SP + SFU performance in single-precision floating point operations [''FLOPS<sub>sp+sfu</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following formula: ''FLOPS<sub>sp+sfu</sub>'' ˜ f × n × 3. Alternative formula:  ''FLOPS<sub>sp+sfu</sub>'' ˜ f × m × ( 8 SPs * 2 (MAD) + 4 * 2 SFUs ). [''m''] - SM count.
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, MAD - ADD+MUL.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 305M
| January 10, 2010
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 525
| 1150
| 1400
| 2.1
| 4.2
| 11.2
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 55
| 14
| 3.93
|-
! style="text-align:left;" | GeForce 310M
| January 10, 2010
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 625
| 1530
| 1600
| 2.5
| 5
| 12.8
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 73
| 14
| 5.21
|-
! style="text-align:left;" | GeForce 315M
| January 5, 2011
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 606
| 1212
| 1600
| 2.42
| 4.85
| 12.8
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 58.18
| 14
| 4.16
|-
! style="text-align:left;" | GeForce 320M
| April 1, 2010
| MCP89
| 40
| Integrated <br> PCIe 2.0 x16
| dedicated video memory: 256 shared <br>system memory: 1595
| 48:16:8
| 450
| 950
| 1066
| 3.6
| 7.2
| 17.056
| DDR3
| 128
| 10.1
| 3.3
| 136.8
| 20
| 6.84
|-
! style="text-align:left;" | GeForce GT 320M
| January 21, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 24:8:8
| 500
| 1100
| 1580
| 4
| 4
| 25.3
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 90
| 14
| 6.43
|-
! style="text-align:left;" | GeForce GT 325M
| January 10, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 450
| 990
| 1600
| 3.6
| 7.2
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 142
| 23
| 6.17
|-
! style="text-align:left;" | GeForce GT 330M
| January 10, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 575
| 1265
| 1600
| 4.6
| 9.2
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 182
| 23
| 7.91
|-
! style="text-align:left;" | GeForce GT 335M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 72:24:8
| 450
| 1080
| 1600
| 3.6
| 10.8
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 233
| 28?
| 8.32?
|-
! style="text-align:left;" | GeForce GTS 350M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 500
| 1249
| 3200
| 4
| 16
| 51.2
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 360
| 28
| 12.86
|-
! style="text-align:left;" | GeForce GTS 360M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 550
| 1436
| 3600
| 4.4
| 17.6
| 57.6
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 413
| 38
| 10.87
|}

===GeForce 400M (4xxM) Series===
The GeForce 400M Series for notebooks architecture.

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF100 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF104/106/108 architecture contains 48 SPs and 8 SFUs. Each SP can fulfill up to two single precision operations FMA per clock. Each SFU can fulfill up to four operations SF per clock. The approximate ratio of operations FMA to operations SF is equal: for GF100 4:1 and for GF104/106/108 3:1. The theoretical shader performance in single-precision floating point operations(FMA) [''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>'' ˜ f × n × 2. Alternative formula: for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × m × (32 SPs × 2(FMA)) and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × m × (48 SPs × 2(FMA)). [''m''] - SM count. Total Processing Power: for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × m ×(32 SPs × 2(FMA) + 4 × 4 SFUs) and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × m × (48 SPs × 2(FMA) + 4 × 8 SFUs) or for GF100 ''FLOPS<sub>sp</sub>'' ˜ f × n × 2.5 and for GF104/106/108 ''FLOPS<sub>sp</sub>'' ˜ f × n × 8 / 3.
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, [[Fused multiply–add|FMA]] - Fused MUL+ADD.
* <sup>3</sup> Each SM in the GF100 also contains 4 texture address units and 16 texture filtering units. Total for the full GF100 64 texture address units and 256 texture filtering units. Each SM in the GF104/106/108 architecture contains 8 texture filtering units for every texture address unit. The complete GF104 die contains 64 texture address units and 512 texture filtering units, the complete GF106 die contains 32 texture address units and 256 texture filtering units and the complete GF108 die contains 16 texture address units and 128 texture filtering units.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 410M
| January 5, 2011
| GF119
| 40
| PCIe 2.0 x16
| 512
| 48:8<sup>3</sup>:4
| 575
| 1150
| 1600
| 2.3
| 4.6
| 12.8
| DDR3
| 64
| 11.0
| 4.4
| 110.4
| 12
|Similar to Desktop GT420 OEM
|-
! style="text-align:left;" | GeForce GT 415M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 512
| 48:8<sup>3</sup>:4
| 500
| 1000
| 1600
| 2
| 4
| 25.6
| DDR3
| 128
| 11.0
| 4.4
| 96
| <12(GPU only)
|Similar to Desktop GT420 OEM
|-
! style="text-align:left;" | GeForce GT 420M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 512
| 96:16<sup>3</sup>:4
| 500
| 1000
| 1600
| 2
| 8
| 25.6
| DDR3
| 128
| 11.0
| 4.4
| 192
| 10-23(GPU only)
|Similar to Desktop GT430
|-
! style="text-align:left;" | GeForce GT 425M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16<sup>3</sup>:4
| 560
| 1120
| 1600
| 2.24
| 8.96
| 25.6
| DDR3
| 128
| 11.0
| 4.4
| 215.04
| 20-23(GPU only)
|Similar to Desktop GT430
|-
! style="text-align:left;" | GeForce GT 435M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 2048
| 96:16<sup>3</sup>:4
| 650
| 1300
| 1600
| 2.6
| 10.4
| 25.6
| DDR3
| 128
| 11.0
| 4.4
| 249.6
| 32-35(GPU only)
|Similar to Desktop GT430/440
|-
! style="text-align:left;" | GeForce GT 445M
| September 3, 2010
| GF106
| 40
| PCIe 2.0 x16
| 1024<br>1536
| 144:24<sup>3</sup>:16<br>144:24<sup>3</sup>:24
| 590
| 1180
| 1600<br>2500
| 9.44<br>14.16
| 14.16
| 25.6<br>60
| DDR3<br>GDDR5
| 128<br>192
| 11.0
| 4.4
| 339.84
| 30-35(GPU only)
|Similar to Desktop GTS450 OEM)
|-
! style="text-align:left;" | GeForce GTX 460M
| September 3, 2010
| GF106
| 40
| PCIe 2.0 x16
| 1536
| 192:32<sup>3</sup>:24
| 675
| 1350
| 2500
| 16.2
| 21.6
| 60
| GDDR5
| 192
| 11.0
| 4.4
| 518.4
| 45-50(GPU only)
|Similar to Desktop GTX550 Ti
|-
! style="text-align:left;" | GeForce GTX 470M
| September 3, 2010
| GF104
| 40
| PCIe 2.0 x16
| 1536
| 288:48<sup>3</sup>:24
| 550
| 1100
| 2500
| 13.2
| 26.4
| 60
| GDDR5
| 256
| 11.0
| 4.4
| 633.6
| 45-50(GPU only)
|Similar to Desktop GTX 460/560SE
|-
! style="text-align:left;" | GeForce GTX 480M
| May 25, 2010
| GF100
| 40
| PCIe 2.0 x16
| 2048
| 352:44<sup>3</sup>:32
| 425
| 850
| 2400
| 13.6
| 18.7
| 76.8
| GDDR5
| 256
| 11.0
| 4.4
| 598.4
| 100(MXM module)
|Similar to Desktop GTX465
|-
! style="text-align:left;" | GeForce GTX 485M
| January 5, 2011
| GF104
| 40
| PCIe 2.0 x16
| 2048
| 384:64<sup>3</sup>:32
| 575
| 1150
| 3000
| 18.4
| 36.8
| 96.0
| GDDR5
| 256
| 11.0
| 4.4
| 883.2
| 100(MXM module)
|Similar to Desktop GTX560 Ti
|}

===GeForce 500M (5xxM) Series===
The GeForce 500M Series for notebooks architecture.

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce GT 520M
| January 5, 2011
| GF119
| 40
| PCIe 2.0 x16
| 1024
| 48:8:4
| 740
| 1480
| 1600
| 2.96
| 5.92
| 12.8
| DDR3
| 64
| 11.0
| 4.4
| 142.08
| 12
|Similar to Desktop 510/520
|-
! style="text-align:left;" | GeForce GT 520M
| 
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 515
| 1030
| 1600
| 2.06
| 8.24
| 12.8
| DDR3
| 64
| 11.0
| 4.4
| 197.76
| 20
| Noticed in [[Lenovo]] laptops, similar to Desktop 530/430/440
|-
! style="text-align:left;" | GeForce GT 520MX
| May 30, 2011
| GF119
| 40
| PCIe 2.0 x16
| 1024
| 48:8:4
| 900
| 1800
| 1800
| 3.6
| 7.2
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 172.8
| 20
|Similar to Desktop 510 & GT520
|-
! style="text-align:left;" | GeForce GT 525M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 600
| 1200
| 1800
| 2.4
| 9.6
| 28.8
| DDR3
| 128
| 11.0
| 4.4
| 230.4
| 20-23
|Similar to Desktop GT 530/430/440
|-
! style="text-align:left;" | GeForce GT 540M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 672
| 1344
| 1800
| 2.688
| 10.752
| 28.8
| DDR3
| 128
| 11.0
| 4.4
| 258.048
| 32-35
|Similar to Desktop GT 530/440
|-
! style="text-align:left;" | GeForce GT 550M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 740
| 1480
| 1800
| 2.96
| 11.84
| 28.8
| DDR3
| 128
| 11.0
| 4.4
| 284.16
| 32-35
|Similar to Desktop GT 530/440
|-
! style="text-align:left;" | GeForce GT 555M
| January 5, 2011
| GF106<br><br>GF108
| 40
| PCIe 2.0 x16
| 1536<br>2048<br>1024
| 144:24:24<br>144:24:16<br>96:16:4
| 590<br>650<br>753
| 1180<br>1300<br>1506
| 1800<br>1800<br>3138
| 14.6<br>10.4<br>3
| 14.6<br>15.6<br>12
| 43.2<br>28.8<br>50.2
| DDR3<br>DDR3<br>GDDR5
| 192<br>128<br>128
| 11.0
| 4.4
| 339.84<br>374.4<br>289.15
| 30-35
|Similar to Desktop GT545
|-
! style="text-align:left;" | GeForce GTX 560M
| May 30, 2011
| GF116
| 40
| PCIe 2.0 x16
| 2048<br>1536, 3072
| 192:32:16<br>192:32:24
| 775
| 1550
| 2500
| 18.6
| 24.8
| 40.0<br>60.0
| GDDR5
| 128<br>192
| 11.0
| 4.4
| 595.2
| 75
|Similar to Desktop GTX 550Ti
|-
! style="text-align:left;" | GeForce GTX 570M
| June 28, 2011
| GF114
| 40
| PCIe 2.0 x16
| 1536
| 336:56:24
| 575
| 1150
| 3000
| 13.8
| 32.2
| 72.0
| GDDR5
| 192
| 11.0
| 4.4
| 772.8
| 75
|Similar to Desktop GTX 560
|-
! style="text-align:left;" | GeForce GTX 580M
| June 28, 2011
| GF114
| 40
| PCIe 2.0 x16
| 2048
| 384:64:32
| 620
| 1240
| 3000
| 19.8
| 39.7
| 96.0
| GDDR5
| 256
| 11.0
| 4.4
| 952.3
| 100
|Similar to Desktop GTX 560 Ti
|}

===GeForce 600M (6xxM) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 600 Series |GeForce 600 Series ]]</div>
The GeForce 600M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 610M 
| Dec 2011
| GF119 (N13M-GE)
| 40
| PCIe 2.0 x16
| 1024<br>2048
| 48:8:4
| 900
| 1800
| 1800
| 3.6
| 7.2
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 142.08
| 12
| OEM. Rebadged GT 520MX
|-
! style="text-align:left;" | GeForce GT 620M 
| Apr 2012
| GF117 (N13M-GS)
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 625
| 1250
| 1800
| 2.5
| 10
| 14.4<br>28.8
| DDR3
| 64<br>128
| 11.0
| 4.4
| 240
| 15
| OEM. Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 625M
| October 2012
| GF117 (N13M-GS)
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 625
| 1250
| 1800
| 2.5
| 10
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 240
| 15
| OEM. Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 630M
| Apr 2012
| GF108 (N13P-GL)<br>GF117
| 40<br>28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 660<br>800
| 1320<br>1600
| 1800<br>4000
| 2.6<br>3.2
| 10.7<br>12.8
| 28.8<br>32.0
| DDR3<br>GDDR5
| 128<br>64
| 11.0
| 4.4
| 258.0<br>307.2
| 33
| GF108: OEM. Rebadged GT 540M<br>GF117: OEM Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 635M
| Apr 2012
| GF106 (N12E-GE2)<br>GF116
| 40
| PCIe 2.0 x16
| 2048<br>1536
| 144:24:24
| 675
| 1350
| 1800
| 16.2
| 16.2
| 28.8<br>43.2
| DDR3
| 128<br>192
| 11.0
| 4.4
| 289.2<br>388.8
| 35
| GF106: OEM. Rebadged GT 555M<br>GF116: 144 Unified Shaders
|-
! style="text-align:left;" | GeForce GT 640M LE
| March 22, 2012
| GF108<br>GK107 (N13P-LP)
| 40<br>28
| PCIe 2.0 x16<br>PCIe 3.0 x16
| 1024<br>2048
| 96:16:4<br><br>384:32:16<br>(2 SMX)
| 762<br>500
| 1524<br>500
| 3130<br>1800
| 3<br>8
| 12.2<br>16
| 50.2<br>28.8
| GDDR5<br>DDR3
| 128
| 11.0
| 4.4
| 292.6<br>384
| 32<br>20
| GF108: Fermi<br>GK107: Kepler, Similar to Desktop GTX650 
|-
! style="text-align:left;" | GeForce GT 640M
| March 22, 2012
| GK107 (N13P-GS)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 625
| 625
| 1800<br>4000
| 10
| 20
| 28.8<br>64.0
| DDR3<br>GDDR5
| 128
| 11.0
| 4.4
| 480
| 32
| Kepler, Similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 645M
| October 2012
| GK107 (N13P-GS)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 710
| 710
| 1800<br>4000
| 11.36
| 22.72
| 28.8<br>64.0
| DDR3<br>GDDR5
| 128
| 11.0
| 4.4
| 545
| 32
| Kepler, Similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 650M
| March 22, 2012 
| GK107 (N13P-GT)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 835<br>745<br>900*
| 835<br>745<br>900*
| 1800<br>4000<br>5000*
| 13.4<br>11.9<br>14.4*
| 26.7<br>23.8<br>28.8*
| 28.8<br>64.0<br>80.0*
| DDR3<br>GDDR5
| 128
| 11.0
| 4.4
| 641.3<br>572.2<br>691.2
| 45
| Kepler, Similar to Desktop GTX650<br>*
|-
! style="text-align:left;" | GeForce GTX 660M
| March 22, 2012
| GK107 (N13E-GE)
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 835
| 835
| 5000
| 13.4
| 26.7
| 80.0
| GDDR5
| 128
| 11.0
| 4.4
| 641.3
| 50
| Kepler, Similar to Desktop GTX650<br>
|-
! style="text-align:left;" | GeForce GTX 670M
| April 2012
| GF114 (N13E-GS1-LP)
| 40
| PCIe 2.0 x16
| 1536<br>3072
| 336:56:24
| 598
| 1196
| 3000
| 14.35
| 33.5
| 72.0
| GDDR5
| 192
| 11.0
| 4.4
| 803.6
| 75
| Rebadged GTX 570M, Similar to Desktop GTX 560
|-
! style="text-align:left;" | GeForce GTX 670MX
| October 2012
| GK104 (N13E-GR)
| 28
| PCIe 3.0 x16
| 1536<br>3072
| 960:80:24<br>(5 SMX)
| 600
| 600
| 2800
| 14.4
| 48.0
| 67.2
| GDDR5
| 192
| 11.0
| 4.4
| 1152
| 75
| Kepler architecture, Similar to Desktop GTX 660
|-
! style="text-align:left;" | GeForce GTX 675M
| April 2012
| GF114 (N13E-GS1)
| 40
| PCIe 2.0 x16
| 2048
| 384:64:32
| 620
| 1240
| 3000
| 19.8
| 39.7
| 96.0
| GDDR5
| 256
| 11.0
| 4.4
| 952.3
| 100
| Rebadged GTX 580M, Similar to Desktop GTX 560Ti
|-
! style="text-align:left;" | GeForce GTX 675MX
| October 2012
| GK104  (N13E-GSR)
| 28
| PCIe 3.0 x16
| 4096
| 960:80:32<br>(5 SMX)
| 600
| 600
| 3600
| 19.2
| 48.0
| 115.2
| GDDR5
| 256
| 11.0
| 4.4
| 1152
| 100
| Kepler architecture, Similar to Desktop GTX 660
|-
! style="text-align:left;" | GeForce GTX 680M
| June 4, 2012
| GK104 (N13E-GTX)
| 28
| PCIe 3.0 x16
| 4096
| 1344:112:32<br>(7 SMX)
| 720
| 720
| 3600
| 23
| 80.6
| 115.2
| GDDR5
| 256
| 11.0
| 4.4
| 1935.4
| 100
| Kepler architecture, Similar to Desktop GTX 670
|-
! style="text-align:left;" | GeForce GTX 680MX
| October 23, 2012
| GK104
| 28
| PCIe 3.0 x16
| 4096
| 1536:128:32<br>(8 SMX)
| 720
| 720
| 5000
| 23
| 92.2
| 160
| GDDR5
| 256
| 11.0
| 4.4
| 2234.3
| 122
| Kepler architecture, Similar to Desktop GTX 680
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

===GeForce 700M (7xxM) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 700 Series |GeForce 700 Series ]]</div>
The GeForce 700M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 710M
| Jan 2013
| GF117
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 800
| 1600
| 1800
| 3.2
| 12.8
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 307.2
| 12
| OEM. Similar to Mobile 620 & Desktop 530
|-
! style="text-align:left;" | GeForce GT 720M
| April 1, 2013
| GF117
| 28
| PCIe 2.0 x16
| 2048
| 96:16:4
| 938
| 1876
| 2000
| 3.8
| 15.0
| 16.0
| DDR3
| 64
| 11.0
| 4.4
| 360.19
| ?
| OEM. Similar to Mobile 625/630 & Desktop 620
|-
! style="text-align:left;" | GeForce GT 730M
| Jan 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 719
| 719
| 2000
| 5.8
| 23.0
| 16.0
| DDR3
| 128
| 11.0
| 4.4
| 552.2
| 33
| Kepler, similar to Desktop GT640
|-
! style="text-align:left;" | GeForce GT 735M
| April 1, 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 889
| 889
| 2000
| 7.11
| 28.4
| 16.0
| DDR3
| 64
| 11.0
| 4.4
| 682.8 
| ?
| Kepler, similar to Desktop GT640
|-
! style="text-align:left;" | GeForce GT 740M
| April 1, 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 980
| 980
| 1800
| 7.84
| 31.4
| 14.4
| DDR3
| 64
| 11.0
| 4.4
| 752.6
| ?
| Similar or slightly slower than GK 107.
|-
! style="text-align:left;" | GeForce GT 740M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 810 
| 810 
| 1800<br>5000
| 12.96
| 25.92
| 28.8<br>80
| DDR3/GDDR5 
| 128
| 11.0
| 4.4
| 622.1
| 45
| Kepler, similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 745M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 837 
| 837
| 2000<br>5000
| 13.4
| 26.8
| 32<br>80
| DDR3/GDDR5
| 128
| 11.0
| 4.4
| 642.8
| 45
| Kepler, similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 750M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 967
| 967
| 2000<br>5000
| 15.5
| 30.9
| 32<br>80
| DDR3/GDDR5
| 128
| 11.0
| 4.4
| 742.7
| 50
| Kepler, similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 755M 
| ?
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 980?
| 980?
| 5400
| 15.7
| 31.4
| 86.4
| GDDR5
| 128
| 11.0
| 4.4
| 752.64
| 50
| Kepler, similar to Desktop GTX650
|-
! style="text-align:left;" | GeForce GTX 760M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 2048
| 768:64:16<br>(4 SMX)
| 657
| 657
| 4000
| 10.5
| 42.1
| 64
| GDDR5
| 128
| 11.0
| 4.4
| 1009.2
| 55
| Kepler, similar to Desktop GTX 650Ti
|-
! style="text-align:left;" | GeForce GTX 765M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 2048
| 768:64:16<br>(4 SMX)
| 850
| 850
| 4000
| 13.6
| 54.4
| 64
| GDDR5
| 128
| 11.0
| 4.4
| 1305.6
| 65
| Kepler, similar to Desktop GTX 650Ti
|-
! style="text-align:left;" | GeForce GTX 770M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 3072
| 960:80:24<br>(5 SMX)
| 811
| 811
| 4000
| 19.5
| 64.9
| 96
| GDDR5
| 192
| 11.0
| 4.4
| 1557.1
| 75
| Kepler, similar to Desktop GTX660
|-
! style="text-align:left;" | GeForce GTX 775M
| Sep 2013
| GK104
| 28
| PCIe 3.0 x16
| 4096
| 1344:112:32<br>(7 SMX)
| 719
| 719
| 3600
| 23.0
| 92.0
| 115.2
| GDDR5
| 256
| 11.0
| 4.4
| 1932.7
| 100
| Kepler, similar to Desktop GTX670
|-
! style="text-align:left;" | GeForce GTX 780M
| May 2013
| GK104
| 28
| PCIe 3.0 x16
| 4096
| 1536:128:32<br>(8 SMX)
| 823
| 823
| 5000
| 26.3
| 105.3
| 160
| GDDR5
| 256
| 11.0
| 4.4
| 2528.3
| 122
| Kepler, similar to Desktop GTX770
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

===GeForce 800M (8xxM) Series===
<div class="rellink relarticle mainarticle">Main article: [[GeForce 800 Series |GeForce 800 Series ]]</div>
The GeForce 800M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

*<sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 820M 
| February 2014
| GF117
| 28
| PCIe 2.0 x16
| 2048
| 96:16:4
| 719-954
| 1438-1908
| 2000
| 2.9-3.8
| 11.5-15.3
| 16
| DDR3
| 64
| 11.0
| 4.4
| 276.1-366.3
| 
| 
|-
! style="text-align:left;" | GeForce 830M 
| March 12, 2014
| GM108
| 28
| PCIe 3.0 x16
| 2048
| 256:16:8<br>(2 SMM)
| 
| 
| 2000
| 
| 
| 
| DDR3
| 64
| 11.2
| 4.4
| 
| 
| 
|-
! style="text-align:left;" | GeForce 840M 
| March 12, 2014
| GM108
| 28
| PCIe 3.0 x16
| 2048
| 384:24:8<br>(3 SMM)
| 1029
| 1029
| 2000
| 8.2
| 24.7
| 16
| DDR3
| 64
| 11.2
| 4.4
| 790.3
| 
| 
|-
! style="text-align:left;" | GeForce GTX 850M 
| March 12, 2014
| GM107
| 28
| PCIe 3.0 x16
| 2048
| 640:40:16<br>(5 SMM)
| 936+Boost
| 936+Boost
| 5000
| 14.0
| 35.0
| 80
| GDDR5
| 128
| 11.2
| 4.4
| 1198.1
| 
| 
|-
! style="text-align:left;" | GeForce GTX 860M 
| March 12, 2014
| GM107<br>GK104
| 28
| PCIe 3.0 x16
| 2048
| 640:40:16<br>(5 SMM)<br>1152:96:16<br>(6 SMX)
| 1029+Boost<br>797+Boost
| 1029+Boost<br>797+Boost
| 5000
| 16.5<br>12.8
| 41.2<br>76.5
| 80
| GDDR5
| 128
| 11.2<br>11.0
| 4.4
| 1317.1<br>1836.3
| 
| 
|-
! style="text-align:left;" | GeForce GTX 870M 
| March 12, 2014
| GK104
| 28
| PCIe 3.0 x16
| 3072
| 1344:112:32<br>(7 SMX)
| 941+Boost
| 941+Boost
| 5000
| 30.1
| 105.4
| 120
| GDDR5
| 192
| 11.0
| 4.4
| 2529.4
| 
| 
|-
! style="text-align:left;" | GeForce GTX 880M 
| March 12, 2014
| GK104
| 28
| PCIe 3.0 x16
| 4096<br>8192
| 1536:128:32<br>(8 SMX)
| 954+Boost
| 954+Boost
| 5000
| 30.5
| 122.1
| 160
| GDDR5
| 256
| 11.0
| 4.4
| 2930.7
| 
| 
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

==Comparison table: Workstation GPUs==

===Quadro===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro
|NV10GL
|220
|AGP 4x
|64
|135
|135
|166
|0:4:4:4
|0.54
|0.54
|2.66
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 MXR
|NV11GL
|180
|AGP 4x
|64
|175
|175
|183
|0:2:4:4
|0.7
|0.7
||2.93
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 EX
|NV11GL
|180
|AGP 4x
|64
|175
|175
|166
|0:2:4:4
|0.7
|0.7
|2.7
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 PRO
|NV15GL
|150
|AGP 4x
|64
|250
|250
|400
|0:4:8:8
|2
|2
|6.4
|DDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro DCC
||NV20GL
|180
|AGP 4x
|128
|200
|200
|460
|1:4:8:8
|1.6
|1.6
|7.4
|DDR
|128
|
|
|8
|1.4
|
|
|-
!Quadro4 380XGL
|NV18GL
|150
|AGP 8x
|128
|275
|275
|513
|0:2:4:4
|1.1
|1.1
|8.2
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 500XGL
|NV17GL
|150
|AGP 4x
|128
|250
|250
|166
|0:2:4:4
|1
|1
|2.7
|SDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 550XGL
|NV17GL
|150
|AGP 4x
|64
|270
|270
|400
|0:2:4:4
|1.08
|1.08
|6.4
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 580XGL
|NV18GL
|150
|AGP 8x
|64
|300
|300
|400
|0:2:4:4
|1.2
|1.2
|6.4
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 700XGL
|NV25
|150
|AGP 4x
|64
|275
|275
|550
|2:4:8:8
|2.2
|2.2
|8.8
|DDR
|128
|
|
|8
|1.4
|
|
|-
!Quadro4 750XGL
|NV25
|150
|AGP 4x
|128
|275
|275
|550
|2:4:8:8
|2.2
|2.2
|8.8
|DDR
|128
|
|
|8
|1.5
|
|Stereo Display
|-
!Quadro4 900XGL
|NV25
|150
|AGP 4x
|128
|300
|300
|650
|2:4:8:8
|2.4
|2.4
|10.4
|DDR
|128
|
|
|8
|1.4
|
|Stereo Display
|-
!Quadro4 980XGL
|NV28GL
|150
|AGP 8x
|128
|300
|300
|650
|2:4:8:8
|2.4
|2.4
|10.4
|DDR
|128
|
|
|8
|1.4
|
|Stereo Display
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | TDP (Watts)
! rowspan=2 | Features
|-
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | API support (version)
|}

===Quadro FX Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1*</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 500
|NV34GL
|150
|AGP 8x
|128
|270
|270
|480
|1:2:2:2<br>*:4:4:4
|1.08
|1.08
|7.687
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 600
|NV34GL
|150
|PCI
|256
|350
|350
|800
|1:2:2:2<br>*:4:4:4
|1
|1
|7.8
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 700
|NV35GL
|150
|AGP 8x
|128
|275
|275
|275
|1:2:2:2<br>*:4:4:4
|1.1
|1.1
|4.4
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 1000
|NV30GL
|130
|AGP 8x
|128
|300
|300
|300
|2:4:8:8
|2.4
|2.4
|9.6
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 1100
|NV36GL
|130
|AGP 8x
|256
|425
|425
|325
|3:2:2:2<br>*:4:4:4
|1.7
|1.7
|5.2
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 2000
|NV30GL
|130
|AGP 8x
|128
|400
|400
|800
|2:4:8:8
|3.2
|3.2
|12.8
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 3000
|NV35GL
|130
|AGP 8x
|256
|400
|400
|850
|3:4:8:8
|3.2
|3.2
|27.2
|DDR
|256
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 3000G
|NV35GL
|130
|AGP 8x
|256
|400
|400
|850
|3:4:8:8
|3.2
|3.2
|27.2
|DDR
|256
|
|
|9.0
|2.0
|
|Stereo Display, [[Genlock]]
|-
!Quadro FX 4000
|NV40GL
|130
|AGP 8x
|256
|375
|375
|1000
|5:12:12:8
|3
|4.5
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|142
|Stereo Display
|-
!Quadro FX 4000 SDI
|NV40GL
|130
|AGP 8x
|256
|375
|375
|1000
|5:12:12:8
|3
|4.5
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|
|Stereo Display, Genlock
|}

===Quadro FX (x300) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 330
|NV37GL
|150
|PCIe x16
|64
|250
|250
|400
|2:4:4:2
|1
|1
|3.2
|DDR
|128
|
|
|9.0
|2.0
|21
|
|-
!Quadro FX 1300
|NV41
|130
|PCIe x16
|128
|350
|350
|550
|3:8:8:8
|2.8
|2.8
|8.8
|DDR
|256
|
|
|9.0c
|2.1
|55
|
|}

===Quadro FX (x400) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 540
|NV43GL
|90
|PCIe x16
|128
|300
|300
|550
|4:8:8:8
|2.4
|2.4
|8.8
|GDDR3
|128
|
|
|9.0c
|2.1
|35
|
|-
!Quadro FX 1400
|NV41
|130
|PCIe x16
|128
|350
|350
|600
|5:12:12:8
|2.8
|4.2
|19.2
|DDR
|256
|
|
|9.0c
|2.1
|70
|Stereo Display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3400
|NV45GL
|130
|PCIe x16
|256
|350
|350
|900
|6:16:16:16
|5.6
|5.6
|28.8
|GDDR3
|256
|
|
|9.0c
|2.1
|101
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3450
|NV41
|130
|PCIe x16
|256
|425
|425
|1000
|5:12:12:8
|3.4
|5.1
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|83
|Stereo display, [[Scalable Link Interface|SLI]]
|}

===Quadro FX (x500) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 350
|G72GL
|90
|PCIe x16
|128
|550
|550
|810
|3:4:4:2
|1.1
|1.1
|6.48
|DDR2
|64
|
|
|9.0c
|2.1
|21
|
|-
!Quadro FX 550
|NV43GL
|90
|PCIe x16
|128
|360
|360
|800
|4:8:8:8
|2.88
|2.88
|12.8
|GDDR3
|128
|
|
|9.0c
|2.1
|25
|
|-
!Quadro FX 1500
|G71
|90
|PCIe x16
|256
|375
|375
|800
|7:20:20:16
|6
|7.5
|40.0
|GDDR3
|256
|
|
|9.0c
|2.1
|65
|
|-
!Quadro FX 3500
|G71GL
|90
|PCIe x16
|256
|470
|470
|1320
|7:20:20:16
|7.52
|9.4
|42.2
|GDDR3
|256
|
|
|9.0c
|2.1
|80
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4500
|G70
|110
|PCIe x16
|512
|470
|470
|1050
|8:24:24:16
|7.52
|11.28
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|109
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 4500X2
|G70
|110
|PCIe x16
|1024
|470
|470
|1050
|2x 8:24:24:16
|15.04
|22.56
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|145
|Stereo display, Genlock
|-
!Quadro FX 4500 SDI
|G70
|110
|PCIe x16
|512
|470
|470
|1050
|8:24:24:16
|7.52
|11.28
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|116
|Stereo display, Genlock
|-
!Quadro FX 5500
|G71
|90
|PCIe x16
|1024
|700
|700
|1050
|8:24:24:16
|11.2
|16.8
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|96
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 5500 SDI
|G71
|90
|PCIe x16
|1024
|700
|700
|1050
|8:24:24:16
|11.2
|16.8
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|104
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|}

===Quadro FX (x600) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 560
|G73GL
|90
|PCIe x16
|128
|350
|350
|1200
|5:12:12:8
|2.8
|4.2
|19.2
|GDDR3
|128
|
|
|9.0c
|2.1
|30
|
|-
!Quadro FX 4600<sup>2</sup>
|G80
|90
|PCIe x16
|768
|500
|1200
|1400
|96:24:24
|12
|24
|67.2
|GDDR3
|384
|345
| -
|10.0
|3.3
|134
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 4600 SDI<sup>2</sup>
|G80
|90
|PCIe x16
|768
|500
|1200
|1400
|96:24:24
|12
|24
|67.2
|GDDR3
|384
|345
| -
|10.0
|3.3
|154
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 5600<sup>2</sup>
|G80
|90
|PCIe 2.0 x16
|1536
|600
|1350
|1600
|128:32:24
|14.4
|38.4
|76.8
|GDDR3
|384
|518.4
| -
|10.0
|3.3
|171
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|}

===Quadro FX (x700) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 370
|G84
|80
|PCIe x16
|256
|360
|720
|1000
|16:8:4
|1.44
|2.88
|6.4
|DDR2
|64
|34.56
| -
|10.0
|3.3
|35
|
|-
!Quadro FX 370 LP
|G86
|80
|PCIe x16
|256
|540
|1080
|1000
|8:8:4
|2.16
|4.32
|8
|DDR2
|64
|25.92
| -
|10.0
|3.3
|25
|DMS-59 for two Single Link DVI
|-
!Quadro FX 470
|MCP7A-U
|65
|PCIe 2.0 x16<br>(Integrated)
|Up to 256MB from system memory.
|580
|1400
|800<br>(system memory)
|16:8:4
|2.32
|4.64
|12.8
|DDR2
|128
|67.2
| -
|10.0
|3.3
|30
|based on GeForce 9400 mGPU
|-
!Quadro FX 570
|G84GL
|80
|PCIe x16
|256
|460
|920
|800
|16:8:8
|3.68
|3.68
|12.8
|DDR2
|128
|44.1
| -
|10.0
|3.3
|38
|
|-
!Quadro FX 1700
|G84GL
|80
|PCIe x16
|512
|460
|920
|800
|32:16:8
|3.68
|7.36
|12.8
|DDR2
|128
|88.32
| -
|10.0
|3.3
|42
|
|-
!Quadro FX 3700
|G92
|65
|PCIe 2.0 x16
|512
|500
|1250
|1600
|112:56:16
|8
|28
|51.2
|GDDR3
|256
|420
| -
|10.0
|3.3
|78
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4700X2
|2xG92
|65
|PCIe 2.0 x16
|2x1024
|500
|1250
|1600
|2x(128:64:16)
|2x8
|2x32
|2x51.2
|GDDR3
|2x256
|2x480
| -
|10.0
|3.3
|226
|
|-
!Quadro VX 200
|G92
|65
|PCIe 2.0 x16
|512
|450
|1125
|1600
|112:56:16
|8
|28
|51.2
|GDDR3
|256
|420
| -
|10
|3.3
|75
|2× Dual-link DVI, S-Video, optimised for [[AutoCAD|Autodesk AutoCAD]]
|}

===Quadro FX (x800) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 380
|G96
|65
|PCIe 2.0 x16
|256
|450
|1100
|1400
|16:8:8
|3.6
|3.6
|22.4
|GDDR3
|128
|52.8
| -
|10.0
|3.3
|34
|Two Dual Link DVI, no DisplayPort
|-
!Quadro FX 380 LP
|GT218GL
|40
|PCIe 2.0 x16
|512
|589
|1402
|1600
|16:8:4
|2.356
|4.712
|12.8
|GDDR3
|64
|67.296
| -
|10.1
|3.3
|28
|DisplayPort, Dual Link DVI
|-
!Quadro FX 580
|G96
|65
|PCIe 2.0 x16
|512
|450
|1125
|1600
|32:16:8
|3.6
|7.2
|25.6
|GDDR3
|128
|108
| -
|10.0
|3.3
|40
|Dual DisplayPort, Dual Link DVI
|-
!Quadro FX 1800
|G100GL-U(G94)
|65
|PCIe 2.0 x16
|768
|550
|1375
|1600
|64:32:12
|6.6
|17.6
|38.4
|GDDR3
|192
|264
| -
|10.0
|3.3
|59
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3800
|GT200GL
|55
|PCIe 2.0 x16
|1024
|602
|1204
|1600
|192:64:16
|9.632
|38.528
|51.2
|GDDR3
|256
|693.504
|86.688
|10.0
|3.3
|108
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4800
|GT200GL
|55
|PCIe 2.0 x16
|1536
|602
|1204
|1600
|192:64:24
|14.448
|38.528
|76.8
|GDDR3
|384
|693.504
|86.688
|10.0
|3.3
|150
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 5800
|GT200GL
|55
|PCIe 2.0 x16
|4096
|648
|1296
|1600
|240:80:32
|20.736
|51.840
|102.4
|GDDR3
|512
|933.12
|116.64
|10.1
|3.3
|189
|Stereo DP two Dual Link DVI, DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro CX
|GT200GL
|55
|PCIe 2.0 x16
|1536
|602
|1204
|1600
|192:64:24
|14.448
|38.528
|76.8
|GDDR3
|384
|693.504
|86.688
|10.0
|3.3
|150
|Display Port and dual-link DVI Output, optimised for [[Cs4|Adobe Creative Suite 4]]
|}

===Quadro x000 Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>4</sup> Each SM in the Fermi architecture contains 4 texture filtering units for every texture address unit. Total for the full GF100 64 texture address units and 256 texture filtering units
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 400
|GT216GL
|40
|PCIe 2.0 x16
|512
|450
|1125
|1540
|48:16:4
|1.8
|7.2
|12.3
|DDR3
|64
|108
| -
|10.1
|3.3
|32
|DisplayPort, Dual Link DVI
|-
!Quadro 600
|GF108GL
|40
|PCIe 2.0 x16
|1024
|640
|1280
|1600
|96:16<sup>4</sup>:4
|2.56
|10.24
|25.6
|DDR3
|128
|245.76
| -
|11.0
|4.3
|40
|DisplayPort, Dual Link DVI
|-
!Quadro 2000
|GF106GL (GF106-875)
|40
|PCIe 2.0 x16
|1024
|625
|1250
|2600
|192:32<sup>4</sup>:16
|10
|20
|41.6
|GDDR5
|128
|480
| -
|11.0
|4.3
|62
|Stereo DP Dual Link DVI, Dual DisplayPort
|-
!Quadro 4000
|GF100
|40
|PCIe 2.0 x16
|2048
|475
|950
|2800
|256:32<sup>4</sup>:32
|15.2
|15.2
|89.6
|GDDR5
|256
|486.4
|243
|11.0
|4.3
|142
|
|-
!Quadro 5000
|GF100
|40
|PCIe 2.0 x16
|2560
|513
|1026
|3000
|352:44<sup>4</sup>:40
|20.53
|22.572
|120
|GDDR5
|320
|722.304
|359
|11.0
|4.3
|152
|
|-
!Quadro 6000
|GF100
|40
|PCIe 2.0 x16
|6144
|574
|1148
|3000
|448:56<sup>4</sup>:48
|27.552
|32.144
|144
|GDDR5
|384
|1028.608
|515
|11.0
|4.3
|204
|
|-
!Quadro 7000
|GF110
|40
|PCIe 2.0 x16
|6144
|651
|1301
|3696
|512:64<sup>4</sup>:48
|31.248
|41.7
|177
|GDDR5
|384
|1332
|667
|11.0
|4.3
|204
|
|}

===Quadro Kxxx Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 410
|GK107
|28
|PCIe 3.0 x16
|512
|706
|706
|1800
|192:16:8<br>(1 SMX)
|
|
|14.4
|DDR3
|64
|
|
|11.0
|4.4
|38
|
|-
!Quadro K600
|GK107
|28
|PCIe 2.0 x16
|1024
|876
|876
|891<br>(1782) 
|192:16:16<br>(1 SMX)
|14.0
|14.0
|28.5
|DDR3
|128
|336.38
|
|11.0
|4.4
|41
| 6.3" Card
|-
!Quadro K2000
|GK107
|28
|PCIe 2.0 x16
|2048
|954
|954
|1000<br>(4000) 
|384:32:16<br>(2 SMX)
|15.2
|30.5
|64
|GDDR5
|128
|732.67
|
|11.0
|4.4
|51
| 7.97" Card
|-
|-
!Quadro K2000D
|GK107
|28
|PCIe 2.0 x16
|2048
|954
|954
|1000<br>(4000) 
|384:32:16<br>(2 SMX)
|15.2
|30.5
|64
|GDDR5
|128
|732.67
|
|11.0
|4.4
|51
| 7.97" Card
|-
!Quadro K4000
|GK106
|28
|PCIe 2.0 x16
|3072
|810.5
|810.5
|1404<br>(5616) 
|768:64:24<br>(4 SMX)
|19.4
|51.9
|134.8
|GDDR5
|192
|1244.93
|
|11.0
|4.4
|80
| 9.5" Card
|-
!Quadro K5000
|GK104
|28
|PCIe 2.0 x16
|4096
|706
|706
|1350<br>(5400)
|1536:128:32<br>(8 SMX)
|22.592
|90.368
|172.8
|GDDR5
|256
|2168.832
|90
|11.0
|4.4
|122
| 10.5" Card
|-
!Quadro K6000
|GK110
|28
|PCIe 3.0 x16
|12288
|901.5
|901.5
|1502<br>(6008)
|2880:240:48<br>(15 SMX)
|54.1
|216
|288
|GDDR5
|384
|5196
|1732
|11.0
|4.4
|225
| 10.5" Card
|}

===Quadro NVS===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12*</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!NVS 50
|NV18
|150
|AGP 4x/PCI
|64
|250
|250
|200
|0:2:4:2
|0.5
|1.0
|1.6
|DDR
|32
|
|7
|1.2
|
|[[DVI-I]], [[S-Video]]
|-
!NVS 100
|NV17
|150
|AGP 4x/PCI
|64
|
|
|333
|0:2:4:2
|
|
|5.328
|DDR
|128
|
|7
|1.2
|
|2x DVI-I, [[VGA]], S-Video
|-
!NVS 200
|NV17
|150
|AGP 4x/PCI
|64
|250
|250
|250
|0:2:4:2
|0.5
|1.0
|8.0

|DDR
|128
|
|7
|1.2
|
|[[Low Force Helix|LFH-60]]
|-
!NVS 210S
|MCP51
|90
|Integrated
|Up to 256 from system memory
|425
|
|
|1:2:2:1
| 0.425
| 0.850
|
|DDR
|128
|
|9.0c
|1.2
|
|[[Digital Visual Interface|DVI]] + [[VGA]]
|-
!NVS 280
|NV34GL
|150
|PCI-Express ×16/AGP 8× / PCI
|64
|275
|275
|250
|0:2:4:2/<br>1:2:2:2 *:4:4:4
|0.55
|1.1
|8.0
|DDR
|128
|
|9.0
|1.5
|13
|[[DMS-59]]
|-
!NVS 285
|NV44
|110
|PCI-Express ×1/×16
|128
|275
|275
|275
|3:4:4:2
|0.55
|1.1
|8.8
|DDR
|128
|
|9.0
|2.1
|18
|[[DMS-59]]
|-
!NVS 290
|G86
|80
|PCI-Express ×1/×16
|256
|460
|920
|800
|16:8:4
|1.84
|3.68
|6.4
|DDR2
|64
|44.16
|10
|3.3
|21
|[[DMS-59]]
|-
!NVS 295
|G98
|65
|PCI-Express ×1/×16
|256
|550
|1300
|1400
|8:8:4
|2.2
|4.4
|11.2
|GDDR3
|64
|31.2
|10
|3.3
|23
|2× DisplayPort or 2× DVI-D
|-
!NVS 300
|GT218
|40
|PCI-Express ×1/×16
|512
|589
|1402
|1580
|16:8:4
|2.356
|4.712
|12.64
|DDR3
|64
|67.3
|10.1
|3.3
|17.5
|[[DMS-59]]
|-
!NVS 310
|GF119
|40
|PCI-Express ×16
|512
|
|
|1750
|48:8:4
|
|
|14
|DDR3
|64
|
|11.0
|4.4
|19.5
|Coming soon. Product listed on nvidia website, but not yet in stock.
|-
!NVS 315
|GF119
|40
|PCI-Express ×16
|1024
|
|
|1800
|48:8:4
|
|
|14
|GDDR3
|64
|
|11.0
|4.4
|19.5
|[[DMS-59]]
|-
!NVS 400
|2× NV17
|150
|PCI
|2× 64
|220
|220
|343
|2× 0:2:4:2
|2× 0.44
|2× 0.88
|2× 11.0
|DDR
|2× 128
|2× 5.328
|
|
|
|DMS-59
|-
!NVS 420
|2×G98
|65
|PCI-Express ×1/×16
|2× 256
|550
|1300
|1400
|2× 8:8:4
|2× 2.2
|2× 4.4
|2× 11.2
|GDDR3
|2× 64
|2× 31.2
|10
|3.3
|40
|through VHDCI to (4× DisplayPort or 4× DVI-D)
|-
!NVS 450
|2×G98
|65
|PCI-Express ×16
|2× 256
|550
|1300
|1400
|2× 8:8:4
|2× 2.2
|2× 4.4
|2× 11.2
|GDDR3
|2× 64
|2× 31.2
|10
|3.3
|35
|4× DisplayPort or 4× DVI-D
|-
!NVS 510
|GK107
|28
|PCI-Express ×16
|2048
|
|
|1800
|192:16:8<br>(1 SMX)
|
|
|28.5
|GDDR3
|128
|
|11.0
|4.4
|35
|4× miniDisplayPort
|}

===Tesla===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Tesla|NVIDIA Tesla]]</div>
* <sup>1</sup> Specifications not specified by NVIDIA assumed to be based on the [[GeForce 8 series#GeForce 8800|GeForce 8800GTX]]
* <sup>2</sup> Specifications not specified by NVIDIA assumed to be based on the [[GeForce 200 Series#GeForce GTX 200|GeForce GTX 280]]
* <sup>3</sup> Specifications not specified by NVIDIA are assumed to be based on the [[GeForce 400 Series]]
* <sup>4</sup> With ECC on, a portion of the dedicated memory is used for ECC bits, so the available user memory is reduced by 12.5%. (e.g. 3 GB total memory yields 2.625 GB of user available memory.)
* <sup>5</sup> Fermi implements the new [[fused multiply–add]] (FMA) instruction for both 32-bit single-precision and 64-bit double-precision floating point numbers (GT200 supported FMA only in double precision) that improves upon multiply–add by retaining full precision in the intermediate stage.
* <sup>6</sup> Specifications not specified by NVIDIA assumed to be based on the Quadro FX 5800
* For the basic specifications of Tesla, refer to the GPU Computing Processor specifications.
* Due to Tesla's non-output nature, Fillrate and Graphics API compatibility are not applicable.
{| class="wikitable" style="font-size: 85%; text-align: center;"
|-
! rowspan=2 style="width:12em" | Configuration
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Core clock<br>(MHz)
! colspan=2 style="text-align:center;" | Shaders
! colspan=5 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | Processing Power (peak) <br> GFLOPS
! rowspan=2 | Compute capability
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes/Form factor
|-
! Thread Processors<br>(total)
! Clock (MHz)
! Bus type
! Bus width<br>([[bit]])
! Memory<br>([[Megabyte|MB]])
! Clock (MHz)
! Bandwidth<br>(total)<br>([[Gigabyte|GB]]/s)
! [[Single precision floating-point format|Single Precision(SP)]] Total(MUL+ADD+SF)
! [[Single precision floating-point format|Single Precision(SP)]] MAD(MUL+ADD)
! [[Double precision floating-point format|Double Precision(DP)]] [[Fused multiply–add|FMA]]
|- valign="top"
! style="text-align:left;" | C870<br>GPU Computing Module
| C870<sup>1</sup>
| G80
| 1
| 600
| 128
| 1350
| GDDR3
| 384
| 1536
| 1600
| 76.8
| 518.4
| 345.6
| 0
| 1.0
| 170.9
| Internal GPU <br> (Full-height card)
|- valign="top"
! style="text-align:left;" | D870<br>Deskside Computer
| D870<sup>1</sup>
| G80
| 2
| 600
| 256
| 1350
| GDDR3
| 384
| 2x1536
| 1600
| 153.6
| 2 x 518.4
| 2 x 345.6
| 0
| 1.0
| 520
| Deskside External GPUs
|- valign="top"
! style="text-align:left;" | S870<br>GPU Computing Server
| S870<sup>1</sup>
| G80
| 4
| 600
| 512
| 1350
| GDDR3
| 384
| 4x1536
| 1600
| 307.2
| 4 x 518.4
| 4 x 345.6
| 0
| 1.0
|
| 1U [[19-inch rack|Rackmount]] External GPUs
|- valign="top"
! style="text-align:left;" | C1060<br>GPU Computing Module
| C1060<sup>2</sup>
| GT200
| 1
| 602
| 240
| 1300
| GDDR3
| 512
| 4096
| 1600
| 102.4
| 933.12
| 622.08
| 77.76
| 1.3
| 187.8
| Internal GPU <br> (Full-height card)
|- valign="top"
! style="text-align:left;" | Quadro Plex Visual Computing System
| 2200 D2<sup>6</sup>
| GT200GL
| 2
| 648
| 2 x 240 (480)
| 1296
| GDDR3
| 512
| 2 x 4096 (8192)
| 1600
| 2 x 102.4
| 2 x 933.12
| 2 x 622.08
| 2 x 77.76
| 1.3
|
| 4 dual-link DVI<br>Deskside or 3U rackmount
|- valign="top"
! style="text-align:left;" | Quadro Plex Visual Computing System
| 2200 S4<sup>6</sup>
| GT200GL
| 4
| 648
| 4 x 240 (960)
| 1296
| GDDR3
| 512
| 4 x 4096 (16384)
| 1600
| 4 x 102.4
| 4 x 933.12
| 4 x 622.08
| 4 x 77.76
| 1.3
|
| display readback Via PCI-Express Gen 2.0<br>1U server
|- valign="top"
! style="text-align:left;" | S1070<br>GPU Computing Server
| S1070<sup>2</sup>
| GT200
| 4
| 602
| 4 x 240 (960)
| 1440/1296
| GDDR3
| 512
| 4x4096
| 1538.4
| 4 x 98.5
| 4 x 1036.8
| 4 x 691.2
| 4 x 86.4
| 1.3
| 800
| 1U [[19-inch rack|Rackmount]] External GPUs<br>connect via 2x PCIe (x8 or x16)
|- valign="top"
! style="text-align:left;" | S1075<br>GPU Computing Server
| S1075<sup>2</sup> 
| GT200
| 4
| 602
| 4 x 240 (960)
| 1500
| GDDR3
| 512
| 4x4096
| 1600
| 4 x 102.4
| 4 x 1036.8
| 4 x 691.2
| 4 x 86.4
| 1.3
|
| 1U [[19-inch rack|Rackmount]] External GPUs<br>connect via 1x PCIe (x8 or x16)
|- valign="top"
! style="text-align:left;" | C2050<br>GPU Computing Module
| C2050<sup>3</sup>
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 3072<sup>4</sup>
| 3000
| 144
| 1288
| 1030.4<sup>5</sup>
| 515.2
| 2.0
| 238
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | C2070<br>GPU Computing Module
| C2070<sup>3</sup>
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144<sup>5</sup>
| 3000
| 144
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 247
| Full-height [[video card]]<br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | C2075<br>GPU Computing Module
| C2075
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144
| 3000
| 144
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Full-height [[video card]]<br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2050<br>GPU Computing Module
| M2050
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 3072<sup>5</sup>
| 3092
| 148.4
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Computing Module <br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2070/M2070Q<br>GPU Computing Module
| M2070/M2070Q 
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144<sup>5</sup>
| 3132
| 150.336
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Computing Module<br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2090<br>GPU Computing Module
| M2090
| GF110
| 1
| 650
| 512
| 1300
| GDDR5
| 384
| 6144<sup>5</sup>
| 3700
| 177.4
| 1664
| 1331.2<sup>6</sup>
| 665.6
| 2.0
| 250
| Computing Module <br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | S2050<br>GPU Computing Server
| S2050
| GF100
| 4
| 575
| 4 x 448 (1792)
| 1150
| GDDR5
| 384
| 12288<sup>5</sup>
| 3092
| 4 x 148.4 (593.6)
| 5152
| 4121.6<sup>6</sup>
| 2060.8
| 2.0
| 900
| [[19-inch rack|1U Rack]]<br>[[IEEE 754-2008]] [[Multiply–accumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | K10<br>GPU Computing Module
| K10
| GK104
| 2
| 745
| 2 x 1536 (3072)
| 745
| GDDR5
| 2 x 256
| 2 x 4096
| 5000
| 2 x 160 (320)
| 5340
| 4577
| 190
| 3.0
| 250W
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | K20<br>GPU Computing Module
| K20
| GK110
| 1
| 705
| 2496 FP32, 832 FP64
| 705
| GDDR5
| 320
| 5120
| 5200
| 208
| 4106
| 3519
| 1173
| 3.5
| 225W
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | K20X<br>GPU Computing Module
| K20X
| GK110
| 1
| 732
| 2688 FP32, 896 FP64
| 732
| GDDR5
| 384
| 6144
| 5200
| 250
| 4591
| 3935
| 1312
| 3.5
| 235W
| Internal GPU<br>(Full-height card)
|
|- valign="top"
! style="text-align:left;" | K40<br>GPU Computing Module
| K40
| GK110
| 1
| 745
| 2880 FP32, 960 FP64
| 745
| GDDR5
| 384
| 12288
| 6000
| 288
| 5364
| 4291
| 1430
| 3.5
| 235W
| Internal GPU<br>(Full-height card)
|
|-
! rowspan=2 style="width:12em" | Configuration
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Core clock<br>(MHz)
! colspan=2 style="text-align:center;" | Shaders
! colspan=5 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | Processing Power (peak) <br> GFLOPS
! rowspan=2 | Compute capability
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes/Form factor
|-
! Thread Processors<br>(total)
! Clock (MHz)
! Bus type
! Bus width<br>([[bit]])
! Memory<br>([[Megabyte|MB]])
! Clock (MHz)
! Bandwidth<br>(total)<br>([[Gigabyte|GB]]/s)
! [[Single precision floating-point format|Single Precision(SP)]] Total(MUL+ADD+SF)
! [[Single precision floating-point format|Single Precision(SP)]] MAD(MUL+ADD)
! [[Double precision floating-point format|Double Precision(DP)]] [[Fused multiply–add|FMA]]
|}

==Comparison table: Mobile Workstation GPUs==

===Quadro FX (xxxM) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 350M
|G72GLM
|90
|PCIe 1.0 x16
|256
|450
|450
|900
|3:4:4:2
|0.9
|1.8
|14.4
|GDDR3
|128
|
|9.0c
|2.1
|15
|
|-
!Quadro FX 360M
|G86M
|80
|PCIe 1.0 x16
|256
|400
|800
|1200
|16:8:4
|1.6
|3.2
|9.6
|DDR2
|64
|38.4
|10.0
|3.3
|17
|
|-
!Quadro FX 370M
|G98M
|65
|PCIe 1.0 x16
|256
|550
|1400
|1200
|8:4:4
|2.2
|2.2
|9.6
|GDDR3
|64
|33.6
|10.0
|3.3
|20
|
|-
!Quadro FX 380M
|GT218M
|40
|PCIe 2.0 x16
|512
|625
|1530
|1600
|16:8:4
|2.5
|5
|12.8
|GDDR3
|64
|73.44
|10.1
|3.3
|25
|
|-
!Quadro FX 560M
|G73GLM
|90
|PCIe 1.0 x16
|512
|500
|500
|1200
|5:12:12:8
|4
|6
|19.2
|GDDR3
|128
|
|9.0c
|2.1
|35?
|
|-
!Quadro FX 570M
|G84M
|80
|PCIe 1.0 x16
|512
|475
|950
|1400
|32:16:8
|3.8
|7.6
|22.4
|GDDR3
|128
|91.2
|10.0
|3.3
|45
|
|-
!Quadro FX 770M
|G96M
|65
|PCIe 1.0 x16
|512
|500
|1250
|1600
|32:16:8
|4
|8
|25.6
|GDDR3
|128
|25.6
|10.0
|3.3
|35
|
|-
!Quadro FX 880M
|GT216M
|40
|PCIe 2.0 x16
|1024
|550
|1210
|1600
|48:16:8
|4.4
|8.8
|25.6
|GDDR3
|128
|174.24
|10.1
|3.3
|35
|
|}

===Quadro FX (x500M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|375
|375
|1000
|8:24:24:16
|6
|9
|32
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|-
!Quadro FX 2500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|500
|500
|1200
|8:24:24:16
|8
|12
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|-
!Quadro FX 3500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|575
|575
|1200
|8:24:24:16
|9.2
|13.8
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|}

===Quadro FX (x600M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1600M
|G84M
|80
|PCIe 1.0 x16
|512
|625
|1250
|1600
|32:16:8
|5
|10
|25.6
|GDDR3
|128
|120
|10.0
|3.3
|50?
|
|-
!Quadro FX 3600M
|G92M
|65
|PCIe 1.0 x16
|512
|500
|1250
|1600
|64:32:16<br>96:48:16
|8<br>8
|16<br>24
|51.2
|GDDR3
|256
|240<br>360
|10.0
|3.3
|70
|based on 8800M GTS/<br>8800M GTX
|}

===Quadro FX (x700M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1700M
|G96M
|65
|PCIe 1.0 x16
|512
|625
|1550
|1600
|32:16:8
|5
|10
|25.6
|GDDR3
|128
|148.8
|10.0
|3.3
|50
|
|-
!Quadro FX 2700M
|G94M
|65
|PCIe 1.0 x16
|512
|530
|1325
|1600
|48:24:16
|8.48
|12.72
|51.2
|GDDR3
|256
|190.8
|10.0
|3.3
|65
|
|-
!Quadro FX 3700M
|G92M
|65
|PCIe 1.0 x16
|1024
|550
|1375
|1600
|128:64:16
|8.8
|35.2
|51.2
|GDDR3
|256
|528
|10.0
|3.3
|75
|
|}

===Quadro FX (x800M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1800M
|GT215M
|40
|PCIe 2.0 x16
|1024
|450
|1080
|1600<br>2200
|72:24:8
|3.6
|10.8
|25.6<br>35.2
|GDDR3<br>GDDR5
|128
|233.28
|10.1
|3.3
|45
|
|-
!Quadro FX 2800M
|G92M
|55
|PCIe 2.0 x16
|1024
|500
|1250
|2000
|96:48:16
|8
|16
|64
|GDDR3
|256
|360
|10.0
|3.3
|75
|
|-
!Quadro FX 3800M
|G92M
|55
|PCIe 2.0 x16
|1024
|675
|1688
|2000
|128:64:16
|10.8
|43.2
|64
|GDDR3
|256
|648.192
|10.0
|3.3
|100
|
|}

===Quadro (xxxxM) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup> Each SM in the Fermi architecture contains 4 texture filtering units for every texture address unit
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 500M
|GF108
|40
|PCIe 2.0 x16
|1024
|700
|1400
|1800
|96:16:4
|2.8
|11.2
|28.8
|DDR3
|128
|268.8
|11.0
|4.4
|35
|
|-
!Quadro 1000M
|GF108
|40
|PCIe 2.0 x16
|2048
|700
|1400
|1800
|96:16:4
|2.8
|11.2
|28.8
|DDR3
|128
|268.8
|11.0
|4.4
|45
|
|-
!Quadro 2000M
|GF106
|40
|PCIe 2.0 x16
|2048
|550
|1100
|1800
|192:32:16
|8.8
|17.6
|28.8
|DDR3
|128
|422.4
|11.0
|4.4
|55
|
|-
!Quadro 3000M
|GF104
|40
|PCIe 2.0 x16
|2048
|450
|900
|2500
|240:40:32
|14.4
|18
|80
|GDDR5
|256
|432
|11.0
|4.4
|75
|
|-
!Quadro 4000M
|GF104
|40
|PCIe 2.0 x16
|2048
|475
|950
|2500
|336:56:32
|15.2
|26.6
|80
|GDDR5
|256
|638.4
|11.0
|4.4
|100
|
|-
!Quadro 5000M
|GF100
|40
|PCIe 2.0 x16
|2048
|405
|810
|2400
|320:40:32
|12.96
|16.2
|76.8
|GDDR5
|256
|518.4
|11.0
|4.4
|100
|
|-
!Quadro 5010M
|GF110
|40
|PCIe 2.0 x16
|4096
|450
|900
|2600
|384:48:32
|14.4
|21.6
|83.2
|GDDR5
|256
|691.2
|11.0
|4.4
|100
|
|}

===Quadro (Kx000M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Nvidia Optimus]] <br> Technology
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro K500M
|GK107
|28
|PCIe 3.0 x16
|1024
|850
|850
|1600
|192:16:8<br>(1 SMX)
|6.8
|13.6
|12.8
|DDR3
|64
|326.4
|11.0
|4.4
|Yes
|35
|
|-
!Quadro K1000M
|GK107
|28
|PCIe 3.0 x16
|2048
|850
|850
|1800
|192:16:16<br>(1 SMX)
|13.6
|13.6
|28.8
|DDR3
|128
|326.4
|11.0
|4.4
|Yes
|45
|
|-
!Quadro K2000M
|GK107
|28
|PCIe 3.0 x16
|2048
|745
|745
|1800
|384:32:16<br>(2 SMX)
|11.92
|23.84
|28.8
|DDR3
|128
|572.16
|11.0
|4.4
|Yes
|55
|
|-
!Quadro K3000M
|GK104
|28
|PCIe 3.0 x16
|2048
|654
|654
|2800
|576:48:32<br>(3 SMX)
|20.93
|31.39
|89.6
|GDDR5
|256
|753.41
|11.0
|4.4
|Yes
|75
|
|-
!Quadro K4000M
|GK104
|28
|PCIe 3.0 x16
|4096
|600
|600
|2800
|960:80:32<br>(5 SMX)
|19.2
|48
|89.6
|GDDR5
|256
|1152
|11.0
|4.4
|Yes
|100
|
|-
!Quadro K5000M
|GK104
|28
|PCIe 3.0 x16
|4096
|706
|706
|3000
|1344:112:32<br>(7 SMX)
|22.59
|79.07
|96
|GDDR5
|256
|1897.73
|11.0
|4.4
|Yes
|100
|
|}

===Quadro (Kx100M) Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Nvidia Optimus]] <br> Technology
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro K510M
|GK208
|28
|PCIe 3.0 x8
|1024
|850
|850
|1200 <br> (2400)
|192:16:8<br>(1 SMX)
|
|
|
|GDDR5
|64
|326.4
|11.0
|4.4
|Yes
|30
|
|-
!Quadro K610M
|GK208
|28
|PCIe 3.0 x16
|1024
|980
|980
|1300 <br> (2600)
|192:16:8<br>(1 SMX)
|
|
|
|GDDR5
|64
|376.32
|11.0
|4.4
|Yes
|30
|
|-
!Quadro K1100M
|GK107
|28
|PCIe 3.0 x16
|2048
|716
|716
|1400 <br> (2800)
|384:32:16<br>(2 SMX)
|
|
|
|GDDR5
|128
|549.89
|11.0
|4.4
|Yes
|45
|
|-
!Quadro K2100M
|GK106
|28
|PCIe 3.0 x16
|2048
|654
|654
|1500 <br> (3000)
|576:48:16<br>(3 SMX)
|
|
|
|GDDR5
|128
|753.41
|11.0
|4.4
|Yes
|55
|
|-
!Quadro K3100M
|GK104
|28
|PCIe 3.0 x16
|4096
|680
|680
|800 <br> (3200)
|768:64:32<br>(4 SMX)
|
|
|
|GDDR5
|256
|1044.48
|11.0
|4.4
|Yes
|75
|Similar to GTX 675MX
|-
!Quadro K4100M
|GK104
|28
|PCIe 3.0 x16
|4096
|706
|706
|800 <br> (3200)
|1152:96:32<br>(6 SMX)
|
|
|
|GDDR5
|256
|1626.624
|11.0
|4.4
|Yes
|100
|
|-
!Quadro K5100M
|GK104
|28
|PCIe 3.0 x16
|8192
|771
|771
|900 <br> (3600)
|1536:128:32<br>(8 SMX)
|
|
|
|GDDR5
|256
|2368.51
|11.0
|4.4
|Yes
|100
|
|}

===Mobility Quadro NVS Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
*<sup>2</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS 
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro NVS 110M
|G72M
|90
|PCIe 1.0 x16
|up to 512
|300
|300
|600
|3:4:4:2
|0.6
|1.2
|4.8
|DDR
|64
|
|9.0c
|2.1
|10
|
|-
!Quadro NVS 120M
|G72GLM
|90
|PCIe 1.0 x16
|up to 512
|450
|450
|700
|3:4:4:2
|0.9
|1.8
|5.6
|DDR2
|64
|
|9.0c
|2.1
|10
|
|-
!Quadro NVS 130M
|G86M
|80
|PCIe 2.0 x16
|up to 256
|400?
|800?
|700
|8:4:4
|1.6?
|1.6?
|6.4?
|DDR2
|64
|19.2
|10.0
|3.3
|10
|
|-
!Quadro NVS 135M
|G86M
|80
|PCIe 2.0 x16
|up to 256
|400
|800
|1188
|16:8:4
|1.6
|3.2
|9.504
|GDDR3
|64
|38.4
|10.0
|3.3
|10
|
|-
!Quadro NVS 140M
|G86M
|80
|PCIe 2.0 x16
|up to 512
|400
|800
|1200
|16:8:4
|1.6
|3.2
|9.6
|GDDR3
|64
|38.4
|10.0
|3.3
|10
|
|-
!Quadro NVS 150M
|G98M
|65
|PCIe 2.0 x16
|up to 256
|530
|1300
|1400
|8:4:4
|2.12
|2.12
|11.2
|GDDR3
|64
|31.2
|10.0
|3.3
|10
|
|-
!Quadro NVS 160M
|G98M
|65
|PCIe 2.0 x16
|256
|580
|1450
|1400
|8:8:4
|2.12
|4.24
|11.2
|GDDR3
|64
|34.8
|10.0
|3.3
|12
|
|-
!Quadro NVS 300M
|G72GLM
|90
|PCIe 1.0 x16
|up to 512
|450
|450
|1000
|3:4:4:2
|0.9
|1.8
|8
|DDR2
|64
|
|9.0c
|2.1
|16
|
|-
!Quadro NVS 320M
|G84M
|65
|PCIe 2.0 x16
|up to 512
|575
|1150
|1400
|32:16:8
|4.6
|9.2
|22.4
|GDDR3
|128
|110.4
|10.0
|3.3
|20
|
|-
!Quadro NVS 510M
|G72GLM
|90
|PCIe 1.0 x16
|up to 1024
|500
|500
|1200
|8:24:24:16
|8
|12
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45?
|based on Go 7900 GTX
|-
|}

===Mobility NVS Series===
<div class="rellink relarticle mainarticle">Main article: [[NVIDIA Quadro|NVIDIA Quadro]]</div>
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Mebibyte|MiB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS 
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!NVS 2100M
|GT218M
|40
|PCIe 2.0 x16
|up to 512
|535
|1230
|1600
|16:8:4
|2.14
|4.28
|12.8
|GDDR3
|64
|59.04
|10.1
|3.3
|14
|
|-
!NVS 3100M
|GT218M
|40
|PCIe 2.0 x16
|up to 512
|600
|1470
|1600
|16:8:4
|2.4
|4.8
|12.8
|GDDR3
|64
|70.56
|10.1
|3.3
|14
|based on G210M/310M
|-
!NVS 4200M
|GF119
|40
|PCIe 2.0 x16
|up to 1024
|810
|1620
|1600
|48:8:4
|3.24
|6.48
|12.8
|GDDR3
|64
|155.52
|11
|4.1
|
|based on GT 520M
|-
!NVS 5100M
|GT216M
|40
|PCIe 2.0 x16
|up to 1024
|550
|1210
|1600
|48:16:8
|4.4
|8.8
|25.6
|GDDR3
|128
|174.24
|10.1
|3.3
|35
|-
!NVS 5200M
|GF108
|40/28
|PCIe 2.0 x16
|up to 1024
|625
|1250
|1800
|96:16:4
|2.5
|10
|14.4
|GDDR3
|64
|240
|11
|4.0
|35
|
|-
!NVS 5400M
|GF108
|40/28
|PCIe 2.0 x16
|up to 2048
|660
|1320
|1800
|96:16:4
|2.64
|10.56
|28.8
|GDDR3
|128
|253.44
|11
|4.3
|35
|
|}

==Comparison table: Grid GPUs==
{| class="wikitable" style="font-size: 85%; text-align: center;"
|-
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Thread Processors<br>(total)
! rowspan=2 | Bus Interface
! colspan=2 style="text-align:center;" | Memory
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
|-
! Bus type
! Memory<br>([[Gigabyte|GB]])
|- valign="top"
!style="text-align:left"|GRID K1 
|GK208
|4
|768
|PCIe 3.0 x16
|DDR3
|16
|130
|- valign="top"
! style="text-align:left;"|GRID K2
|GK104-895
|2
|3072
|PCIe 3.0 x16
|GDDR5
|8
|225
|}
* Data from GRID GPUS

==Comparison table: Console GPUs==
<table class="metadata plainlinks ambox ambox-style ambox-No_footnotes" role="presentation"><tr><td class="mbox-image"><div style="width:52px;">[[file:text document with red question mark.svg|50x40px|alt=|link=]]</div></td><td class="mbox-text"><span class="mbox-text-span">This section includes a [[Wikipedia:Citing sources|list of references]], related reading or [[Wikipedia:External links|external links]], but '''the sources of this section remain unclear because it lacks [[Wikipedia:Citing sources#Inline citations|inline citations]]'''.<span class="hide-when-compact"> Please [[Wikipedia:WikiProject Fact and Reference Check|improve]] this article by introducing more precise citations.</span>  <small>''(October 2013)''</small><span class="hide-when-compact"></span></span></td></tr></table>
{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Mebibyte|MiB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application Programming Interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|XGPU([[Xbox (console)|Xbox]]) 
|November 15, 2001
|NV2A
|150
|Integrated
|64
|233
|200
|4:2:8:4
|932
|932
|1864
|116.5
|6.4
|DDR
|128
|8.1
|1.4
|-
!style="text-align:left"|[[RSX 'Reality Synthesizer'|RSX]]([[PS3]]) 
|November 11, 2006
|G70
|90, 65, 40
|FlexIO
|256<br>256
|550
|700 
|24:8:24:8
|74800
|4400
|13200
|1100
|22.4<br>20 (read), 15 (write)
|GDDR3<br>XDR
|128
|N/A
|ES 1.1 w/Cg
|}

*<sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

==See also==

*[[Nvidia]]
*[[Scalable Link Interface]] (SLI)
*[[TurboCache]]
*[[CUDA]]
*[[Comparison of Nvidia chipsets]]
*[[Comparison of AMD graphics processing units]]
*[[Comparison of AMD processors]]
*[[Comparison of AMD chipsets]]
*[[List of Intel chipsets]]
*[[Comparison of Intel processors]]
*[[Comparison of Intel graphics processing units]]

==References==
<div class="reflist columns references-column-count references-column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2; list-style-type: decimal;">
<references group=""></references></div>[[Category:Articles using fixed number of columns in reflist]]

==External links==
*[http://download.nvidia.com/developer/Papers/2005/OpenGL_2.0/NVIDIA_OpenGL_2.0_Support.pdf OpenGL 2.0 support on NVIDIA GPUs (PDF document)]
*[http://developer.download.nvidia.com/opengl/glsl/glsl_release_notes.pdf Release Notes for NVIDIA OpenGL Shading Language Support (PDF document)]
*[http://www.opengl.org/ OpenGL homepage]
*[http://www.microsoft.com/windows/directx/default.mspx Directx homepage]
*[http://www.tomshardware.com/charts/ Benchmarks and comparisons for some consumer graphics cards]
*[http://www.anandtech.com/video/showdoc.aspx?i=2977 AnandTech Comparison of PureVideo HD with VP1 and VP2]
*[http://www.anandtech.com/video/showdoc.aspx?i=2984 AnandTech GeForce 8M Features]
* [http://www.techpowerup.com/forums/showthread.php?t=171000 TechPowerUp! GPU Database]

<table cellspacing="0" class="navbox" style="border-spacing:0;"><tr><td style="padding:2px;"><table cellspacing="0" class="nowraplinks collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit;"><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view">[[Template:Nvidia|<span  title="View this template" style=";;background:none transparent;border:none;;">v</span >]]</li><li class="nv-talk">[[Template talk:Nvidia|<span  title="Discuss this template" style=";;background:none transparent;border:none;;">t</span >]]</li><li class="nv-edit">[//en.wikipedia.org/w/index.php?title=Template:Nvidia&action=edit <span  title="Edit this template" style=";;background:none transparent;border:none;;">e</span >]</li></ul></div><div style="font-size:110%;">[[Nvidia]]</div></th></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd hlist" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="border-spacing:0;"><tr><th scope="col" class="navbox-title" colspan="2" style=";;"><span style="float:left;width:6em;">&nbsp;</span><div style="font-size:110%;">[[List of Nvidia graphics processing units|Graphics processing unit]]s</div></th></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks navbox-subgroup" style="border-spacing:0;"><tr><th scope="row" class="navbox-group">[[Microarchitecture]]s</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
* [[Tesla (microarchitecture)|Tesla]]
* [[Fermi (microarchitecture)|Fermi]]
* [[Kepler (microarchitecture)|Kepler]]
* [[Maxwell (microarchitecture)|Maxwell]]
* [[Pascal (microarchitecture)|Pascal]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Early [[chipset]]s</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[NV1]]
*[[NV2]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">RIVA series</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[RIVA 128]]
*[[RIVA TNT]]
*[[RIVA TNT2]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">[[GeForce|GeForce series]]</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[GeForce 256]]
*[[GeForce 2 Series|2]]
*[[GeForce 3 Series|3]]
*[[GeForce 4 Series|4]]
*[[GeForce FX Series|5]]
*[[GeForce 6 Series|6]]
*[[GeForce 7 Series|7]]
*[[GeForce 8 Series|8]]
*[[GeForce 9 Series|9]]
*[[GeForce 100 Series|100]]
*[[GeForce 200 Series|200]]
*[[GeForce 300 Series|300]]
*[[GeForce 400 Series|400]]
*[[GeForce 500 Series|500]]
*[[GeForce 600 Series|600]]
*[[GeForce 700 Series|700]]
*[[GeForce 800 Series|800]]
*[[GeForce 900 Series|900]]
*[[GeForce 1000 Series|1000]]
*[[GeForce 1100 Series|1100]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Other series</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Nvidia Quadro|Quadro series]]
**[[Nvidia Quadro Plex|Quadro Plex]]
*[[Nvidia Tesla|Tesla series]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Technologies</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Multi-monitor|nView]]
*[[Nvidia 3D Vision|3D Vision]]
*[[Scalable Link Interface|SLI]]
*[[Nvidia Optimus|Optimus]]
*[[TurboCache]]
*[[CUDA]]
*[[PhysX]]
*[[OptiX]]
*SceniX
*CompleX
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Multimedia Acceleration Technologies</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[High-Definition Video Processor]]
*[[Video Processing Engine]]
*[[Nvidia PureVideo|PureVideo]]
</div></td></tr></table><div></div></td></tr></table><div></div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-even hlist" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="border-spacing:0;"><tr><th scope="col" class="navbox-title" colspan="2" style=";;"><span style="float:left;width:6em;">&nbsp;</span><div style="font-size:110%;">[[Motherboard]] [[chipset]]s</div></th></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks navbox-subgroup" style="border-spacing:0;"><tr><th scope="row" class="navbox-group">GeForce Series</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Nvidia Ion|ION]]
*[[GeForce 8-series chipsets|8]]
*9
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">nForce Series</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[nForce|nForce 220/415/420]]
*[[nForce2]]
*[[nForce3]]
*[[nForce4]]
*[[nForce 500]]
*[[nForce 600]]
*[[nForce 700]]
*[[Comparison of Nvidia chipsets#nForce 900|nForce 900]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Technologies</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Enthusiast System Architecture|ESA]]
*[[Serial presence detect#Enhanced Performance Profiles (EPP)|EPP]]
*[[nForce 500#Specifications|LinkBoost]]
*[[Mobile PCI Express Module|MXM]]
*[[SoundStorm]]
</div></td></tr></table><div></div></td></tr></table><div></div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd hlist" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="border-spacing:0;"><tr><th scope="col" class="navbox-title" colspan="2" style=";;"><span style="float:left;width:6em;">&nbsp;</span><div style="font-size:110%;">Other products</div></th></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks navbox-subgroup" style="border-spacing:0;"><tr><th scope="row" class="navbox-group">[[Video game console|Consoles]]</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Xbox (console)#Technical specifications|NV2A]] <small style="font-size:85%;">([[Xbox (console)|Xbox]])</small>
*[[RSX 'Reality Synthesizer'|RSX]] <small style="font-size:85%;">([[PlayStation 3]])</small>
*[[Nvidia Shield]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">[[Central processing unit|CPU]]s</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Project Denver]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Bridge chips</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[NVIDIA BR02|BR02]]
*BR03
*BR04
*NF200
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">[[Handheld electronics|Handheld]]</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[GoForce]]
*[[Tegra]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Software</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*ForceWare
*[[Nvidia System Tools|System Tools]]
*[[Gelato (software)|Gelato]]
*[[Cg_(programming_language)|Cg]]
*[[VDPAU]]
</div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><th scope="row" class="navbox-group">Acquisitions</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[3dfx Interactive]]
*[[Ageia]]
*[[Acer Laboratories Incorporated|ULi]]
*[[mental Images (firm)|Mental Images]]
*[[PortalPlayer]]
*Exluna
*MediaQ
</div></td></tr></table><div></div></td></tr></table><div></div></td></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-even hlist" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;"></div><table cellspacing="0" class="nowraplinks collapsible collapsed navbox-subgroup" style="border-spacing:0;"><tr><th scope="col" class="navbox-title" colspan="2" style=";;"><span style="float:left;width:6em;">&nbsp;</span><div style="font-size:110%;">Key people</div></th></tr><tr style="height:2px;"><td colspan="2"></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px;"><div style="padding:0em 0.25em;">
*[[Jen-Hsun Huang]]
*[[Chris Malachowsky]]
*[[Curtis Priem]]
*[[David Kirk (scientist)|David Kirk]]
*Debora Shoquist
*Dr. Ranga Jayaraman
*Jonah M. Alben
</div></td></tr></table><div></div></td></tr></table></td></tr></table>



[[Category:Computing comparisons|NVIDIA Graphics Processing Units]]
[[Category:Nvidia|*List Of NVIDIA Graphics Processing Units]]
[[Category:Video cards|*List Of NVIDIA Graphics Processing Units]]
